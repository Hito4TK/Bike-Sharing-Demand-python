{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV,LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.style.use('bmh')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['data_set'] = 'train'\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df['data_set'] = 'test'\n",
    "# combine train and test data into one df\n",
    "test_df['registered'] = 0\n",
    "test_df['casual'] = 0\n",
    "test_df['count'] = 0\n",
    "\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "# parse datetime colum & add new time related columns\n",
    "dt = pd.DatetimeIndex(all_df['datetime'])\n",
    "all_df.set_index(dt, inplace=True)\n",
    "\n",
    "# logarithmic transformation of dependent cols\n",
    "# (adding 1 first so that 0 values don't become -inf)\n",
    "for col in ['casual', 'registered', 'count']:\n",
    "    all_df[f'{col}_log'] = np.log(all_df[col] + 1)\n",
    "\n",
    "all_df['date'] = dt.date # yyyymmdd\n",
    "all_df['day'] = dt.day # dd\n",
    "all_df['month'] = dt.month # mm\n",
    "all_df['year'] = dt.year # yyyy\n",
    "all_df['hour'] = dt.hour # hh\n",
    "all_df['dow'] = dt.dayofweek #曜日 Mon:0 Tue:1 Wed:2 Thu:3 Fri:4 Sat:5 Sun:6\n",
    "all_df['woy'] = dt.isocalendar().week #その日の週が年間で見ると何番目の週かを表す数字 [dt.weekofyear]は deprecated\n",
    "\n",
    "# add a count_season column using join\n",
    "by_season = all_df[all_df['data_set'] == 'train'].copy().groupby(['season'])[['count']].agg(sum)\n",
    "by_season.columns = ['count_season']\n",
    "all_df = all_df.join(by_season, on='season')\n",
    "\n",
    "\n",
    "# feature engineer a new column whether its a peak hour or not\n",
    "all_df['peak'] = all_df[['hour', 'workingday']]\\\n",
    "    .apply(lambda df: 3 if ((df['workingday'] == 1 and (df['hour'] == 8 or 17 <= df['hour'] <= 18)) \\\n",
    "                            or (df['workingday'] == 0 and 11 <= df['hour'] <= 17)) else \\\n",
    "                            ( 2 if ((df['workingday'] == 1 and (df['hour'] == 7 or df['hour'] == 9 or df['hour'] == 16 or 19 <= df['hour'] <= 20)) \\\n",
    "                            or (df['workingday'] == 0 and (df['hour'] == 10 or 18 <= df['hour'] <= 19))) else \\\n",
    "                            ( 1 if ((df['workingday'] == 1 and (10 <= df['hour'] <= 15 or 21 <= df['hour'] <= 22)) \\\n",
    "                            or (df['workingday'] == 0 and (8 <= df['hour'] <= 9 or 20 <= df['hour'] <= 23))) else 0)), axis = 1)\n",
    "\n",
    "#ここの修正の仕方は、間違っているので要修正！\n",
    "# sandy\n",
    "#all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "#    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else 0, axis = 1)\n",
    "# 修正後↓\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else df['holiday'], axis = 1)\n",
    "\n",
    "\n",
    "# christmas and others\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday']]\\\n",
    "    .apply(lambda df: 1 if (df['month'] == 12 and df['day'] in [24, 26, 31]) else df['holiday'], axis = 1)\n",
    "all_df['workingday'] = all_df[['month', 'day', 'workingday']]\\\n",
    "    .apply(lambda df: 0 if df['month'] == 12 and df['day'] in [24, 31] else df['workingday'], axis = 1)\n",
    "# これは流石に気づかない気がする。。。気づけない気がする。。。\n",
    "def get_day(day_start):\n",
    "    day_end = day_start + pd.offsets.DateOffset(hours=23)\n",
    "    return pd.date_range(day_start, day_end, freq=\"H\")\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"workingday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"workingday\"] = 1\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"workingday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"workingday\"] = 0\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"holiday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"holiday\"] = 0\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"holiday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"holiday\"] = 1\n",
    "\n",
    "#storms\n",
    "all_df.loc[get_day(datetime(2012, 5, 21)), \"holiday\"] = 1\n",
    "\n",
    "#tornado\n",
    "all_df.loc[get_day(datetime(2012, 6, 1)), \"holiday\"] = 1\n",
    "# from histogram\n",
    "all_df['ideal'] = all_df[['temp', 'windspeed']]\\\n",
    "    .apply(lambda df: 1 if (df['temp'] > 27 and df['windspeed'] < 30) else 0, axis = 1)\n",
    "    \n",
    "all_df['sticky'] = all_df[['humidity', 'workingday']]\\\n",
    "    .apply(lambda df: 1 if (df['workingday'] == 1 and df['humidity'] >= 60) else 0, axis = 1)\n",
    "\n",
    "# temperature\n",
    "all_df.loc[all_df['temp'] < 10,'temp_cat'] = 1\n",
    "all_df.loc[(all_df['temp'] >= 10) & (all_df['temp'] < 15),'temp_cat'] = 2\n",
    "all_df.loc[(all_df['temp'] >= 15) & (all_df['temp'] < 20),'temp_cat'] = 3\n",
    "all_df.loc[(all_df['temp'] >= 20) & (all_df['temp'] < 25),'temp_cat'] = 4\n",
    "all_df.loc[(all_df['temp'] >= 25) & (all_df['temp'] < 30),'temp_cat'] = 5\n",
    "all_df.loc[(all_df['temp'] >= 30) & (all_df['temp'] < 35),'temp_cat'] = 6\n",
    "all_df.loc[(all_df['temp'] >= 35),'temp_cat'] = 7\n",
    "\n",
    "# humidity many category\n",
    "all_df.loc[all_df['humidity'] < 10,'humidity_cat_many'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 10) & (all_df['humidity'] < 20),'humidity_cat_many'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 30),'humidity_cat_many'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 30) & (all_df['humidity'] < 40),'humidity_cat_many'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 50),'humidity_cat_many'] = 4\n",
    "all_df.loc[(all_df['humidity'] >= 50) & (all_df['humidity'] < 60),'humidity_cat_many'] = 5\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 70),'humidity_cat_many'] = 6\n",
    "all_df.loc[(all_df['humidity'] >= 70) & (all_df['humidity'] < 80),'humidity_cat_many'] = 7\n",
    "all_df.loc[(all_df['humidity'] >= 80) & (all_df['humidity'] < 90),'humidity_cat_many'] = 8\n",
    "all_df.loc[(all_df['humidity'] >= 90),'humidity_cat_many'] = 9\n",
    "\n",
    "# humidity not many category\n",
    "all_df.loc[all_df['humidity'] < 20,'humidity_cat_less'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 40),'humidity_cat_less'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 60),'humidity_cat_less'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 80),'humidity_cat_less'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 80),'humidity_cat_less'] = 4\n",
    "\n",
    "# windspeed\n",
    "all_df.loc[all_df['windspeed'] < 5,'wind_cat'] = 0\n",
    "all_df.loc[(all_df['windspeed'] >= 5) & (all_df['windspeed'] < 10),'wind_cat'] = 1\n",
    "all_df.loc[(all_df['windspeed'] >= 10) & (all_df['windspeed'] < 15),'wind_cat'] = 2\n",
    "all_df.loc[(all_df['windspeed'] >= 15) & (all_df['windspeed'] < 20),'wind_cat'] = 3\n",
    "all_df.loc[(all_df['windspeed'] >= 20) & (all_df['windspeed'] < 25),'wind_cat'] = 4\n",
    "all_df.loc[(all_df['windspeed'] >= 25) & (all_df['windspeed'] < 30),'wind_cat'] = 5\n",
    "all_df.loc[(all_df['windspeed'] >= 30) & (all_df['windspeed'] < 35),'wind_cat'] = 6\n",
    "all_df.loc[(all_df['windspeed'] >= 35) & (all_df['windspeed'] < 40),'wind_cat'] = 7\n",
    "all_df.loc[(all_df['windspeed'] >= 40) & (all_df['windspeed'] < 45),'wind_cat'] = 8\n",
    "all_df.loc[(all_df['windspeed'] >= 45),'wind_cat'] = 9\n",
    "\n",
    "# One-hot-Encoding for season\n",
    "season_map = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}\n",
    "all_df['season_name'] = all_df['season'].map(lambda d : season_map[d])\n",
    "temporary = pd.get_dummies(all_df['season_name'])\n",
    "all_df['season_Fall'] = temporary['Fall']\n",
    "all_df['season_Spring'] = temporary['Spring']\n",
    "all_df['season_Summer'] = temporary['Summer']\n",
    "all_df['season_Winter'] = temporary['Winter']\n",
    "\n",
    "# One-hot-Encoding for weather\n",
    "weather_map = {1:'Good', 2:'Normal', 3:'Bad', 4:'Worse'}\n",
    "all_df['weather_name'] = all_df['weather'].map(lambda d : weather_map[d])\n",
    "temporary = pd.get_dummies(all_df['weather_name'])\n",
    "all_df['weather_Good'] = temporary['Good']\n",
    "all_df['weather_Normal'] = temporary['Normal']\n",
    "all_df['weather_Bad'] = temporary['Bad']\n",
    "all_df['weather_Worse'] = temporary['Worse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>sticky</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat_many</th>\n",
       "      <th>humidity_cat_less</th>\n",
       "      <th>wind_cat</th>\n",
       "      <th>season_name</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "      <th>weather_name</th>\n",
       "      <th>weather_Good</th>\n",
       "      <th>weather_Normal</th>\n",
       "      <th>weather_Bad</th>\n",
       "      <th>weather_Worse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  sticky  temp_cat  \\\n",
       "datetime                                                           \n",
       "2011-01-01 00:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 01:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 02:00:00        312498     0      0       0       1.0   \n",
       "\n",
       "                     humidity_cat_many  humidity_cat_less  wind_cat  \\\n",
       "datetime                                                              \n",
       "2011-01-01 00:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 01:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 02:00:00                8.0                4.0       0.0   \n",
       "\n",
       "                    season_name  season_Fall  season_Spring  season_Summer  \\\n",
       "datetime                                                                     \n",
       "2011-01-01 00:00:00      Spring            0              1              0   \n",
       "2011-01-01 01:00:00      Spring            0              1              0   \n",
       "2011-01-01 02:00:00      Spring            0              1              0   \n",
       "\n",
       "                     season_Winter weather_name  weather_Good  weather_Normal  \\\n",
       "datetime                                                                        \n",
       "2011-01-01 00:00:00              0         Good             1               0   \n",
       "2011-01-01 01:00:00              0         Good             1               0   \n",
       "2011-01-01 02:00:00              0         Good             1               0   \n",
       "\n",
       "                     weather_Bad  weather_Worse  \n",
       "datetime                                         \n",
       "2011-01-01 00:00:00            0              0  \n",
       "2011-01-01 01:00:00            0              0  \n",
       "2011-01-01 02:00:00            0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
       "       'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count',\n",
       "       'data_set', 'casual_log', 'registered_log', 'count_log', 'date', 'day',\n",
       "       'month', 'year', 'hour', 'dow', 'woy', 'count_season', 'peak', 'ideal',\n",
       "       'sticky', 'temp_cat', 'humidity_cat_many', 'humidity_cat_less',\n",
       "       'wind_cat', 'season_name', 'season_Fall', 'season_Spring',\n",
       "       'season_Summer', 'season_Winter', 'weather_name', 'weather_Good',\n",
       "       'weather_Normal', 'weather_Bad', 'weather_Worse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of randomly splitting our training data \n",
    "# for cross validation, let's construct a framework that's more\n",
    "# in line with how the data is divvied up for this competition\n",
    "# (given first 19 days of each month, what is demand for remaining days)\n",
    "# so, let's split our training data into 2 time contiguous datasets\n",
    "# for fitting and validating our model (days 1-14 vs. days 15-19).\n",
    "\n",
    "# also, since submissions are evaluated based on the\n",
    "# root mean squared logarithmic error (RMSLE), let's replicate\n",
    "# that computation as we test and tune our model.\n",
    "\n",
    "train_df = all_df[all_df['data_set'] == 'train']\n",
    "test_df = all_df[all_df['data_set'] == 'test']\n",
    "\n",
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def custom_train_valid_split(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    valid = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def prep_train_data(data, input_cols):\n",
    "    X = data[input_cols].values\n",
    "    y_r = data['registered_log'].values\n",
    "    y_c = data['casual_log'].values\n",
    "\n",
    "    return X, y_r, y_c\n",
    "\n",
    "# predict on validation set & transform output back from log scale\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    \n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, input_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, input_cols)\n",
    "\n",
    "            # training and validating\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "    \n",
    "    rmsle = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    \n",
    "    return (np.array(y_pred_comb_l), np.array(y_actual_comb_l), rmsle)\n",
    "\n",
    "\n",
    "# predict on test set & transform output back from log scale\n",
    "def predict_on_test_set(model, input_cols):\n",
    "    \n",
    "    y_pred_comb_l = []\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "            \n",
    "            # prepare training set\n",
    "            print(f'Now,{year_val} {month_val} testing...')\n",
    "            train_df_tmp = train_df.query('year <= @year_val and month <= @month_val')\n",
    "            test_df_tmp = test_df.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_df_tmp, input_cols)\n",
    "\n",
    "            # prepare testing set\n",
    "            X_test = test_df_tmp[input_cols].values\n",
    "            \n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_test)) - 1\n",
    "            \n",
    "            # add casual & registered predictions together\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "    \n",
    "    return np.array(y_pred_comb_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-13 16:14:39,746]\u001b[0m A new study created in memory with name: no-name-213dfc48-0df6-4960-89fb-7bc86c3bcd8b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-13 16:18:02,060]\u001b[0m Trial 0 finished with value: 0.4085897977221024 and parameters: {'reg_alpha': 0.0013292918943162175, 'reg_lambda': 0.07114476009343425, 'num_leaves': 5, 'colsample_bytree': 0.759195090518222, 'subsample': 0.4936111842654619, 'subsample_freq': 1, 'min_child_samples': 0}. Best is trial 0 with value: 0.4085897977221024.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-13 16:20:40,468]\u001b[0m Trial 1 finished with value: 0.390863464603388 and parameters: {'reg_alpha': 0.0396760507705299, 'reg_lambda': 0.006358358856676255, 'num_leaves': 5, 'colsample_bytree': 0.41235069657748147, 'subsample': 0.9819459112971965, 'subsample_freq': 6, 'min_child_samples': 2}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-13 16:23:02,379]\u001b[0m Trial 2 finished with value: 0.40907103197549827 and parameters: {'reg_alpha': 0.0003511356313970409, 'reg_lambda': 0.0003549878832196505, 'num_leaves': 3, 'colsample_bytree': 0.7148538589793427, 'subsample': 0.6591670111852694, 'subsample_freq': 2, 'min_child_samples': 6}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適パラメータ {'reg_alpha': 0.0396760507705299, 'reg_lambda': 0.006358358856676255, 'num_leaves': 5, 'colsample_bytree': 0.41235069657748147, 'subsample': 0.9819459112971965, 'subsample_freq': 6, 'min_child_samples': 2}\n",
      "スコア 0.390863464603388\n",
      "所要時間502.642160654068秒\n"
     ]
    }
   ],
   "source": [
    "# LightGBM with Oputuna for training and validating\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "seed = 42\n",
    "# モデル作成\n",
    "model_r = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "model_c = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "\n",
    "\n",
    "# 学習時fitパラメータ指定\n",
    "\"\"\" fit_params = {'verbose': 0,  # 学習中のコマンドライン出力\n",
    "              'early_stopping_rounds': 10,  # 学習時、評価指標がこの回数連続で改善しなくなった時点でストップ\n",
    "              'eval_metric': 'rmse',  # early_stopping_roundsの評価指標\n",
    "              'eval_set': [(X, y)]  # early_stopping_roundsの評価指標算出用データ\n",
    "              }\n",
    " \"\"\"\n",
    "req_cols = ['season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed', \n",
    "        'day','month', 'year', 'hour', 'dow', 'woy', 'peak', 'ideal',\n",
    "       'sticky', 'temp_cat', 'humidity_cat_many', 'humidity_cat_less','wind_cat'\n",
    "       #'datetime', 'casual', 'registered', 'count','data_set', 'casual_log', 'registered_log', 'count_log', 'date','count_season', \n",
    "       ]\n",
    "\n",
    "\"\"\" gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    #'holiday', 'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "    'hour', 'dow', 'year', 'ideal', #'count_season',\n",
    "]\n",
    " \"\"\"\n",
    "start = time.time()\n",
    "# ベイズ最適化時の評価指標算出メソッド\n",
    "def bayes_objective(trial):\n",
    "    params = {\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 0.1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 6),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 10)\n",
    "    }\n",
    "    # モデルにパラメータ適用\n",
    "    model_r.set_params(**params)\n",
    "    model_c.set_params(**params)\n",
    "    \n",
    "    # cross_val_scoreでクロスバリデーション\n",
    "    \n",
    "\n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, req_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, req_cols)\n",
    "\n",
    "            model_r.fit(X_train,y_train_r,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_r)])\n",
    "            model_c.fit(X_train,y_train_c,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_c)])\n",
    "\n",
    "            # training and validating\n",
    "            #model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            #model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "        \n",
    "    rmsle_lgb = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    return rmsle_lgb\n",
    "\n",
    "# ベイズ最適化を実行\n",
    "study = optuna.create_study(direction='minimize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study.optimize(bayes_objective, n_trials=3)#400)\n",
    "\n",
    "# 最適パラメータの表示と保持\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_trial.value\n",
    "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
    "print(f'所要時間{time.time() - start}秒')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "rf_cols = [\n",
    "    #'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'weather', 'temp_cat', 'wind_cat',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    #'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak'\n",
    "    ]\n",
    "\n",
    "(rf_pred, rf_actual, rf_rmsle) = predict_on_validation_set(rf_model, rf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_pred.shape: (2286,)   rf_actual.shape: (2286,)   rf_rmsle: 0.4155804886847993\n"
     ]
    }
   ],
   "source": [
    "print(f'rf_pred.shape: {rf_pred.shape}   rf_actual.shape: {rf_actual.shape}   rf_rmsle: {rf_rmsle}')\n",
    "#all_df[rf_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    #'holiday', 'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "    'hour', 'dow', 'year', 'ideal', #'count_season',\n",
    "]\n",
    "\n",
    "(gbm_pred, gbm_actual, gbm_rmsle) = predict_on_validation_set(gbm_model, gbm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm_pred.shape: (2286,)   gbm_actual.shape: (2286,)   gbm_rmsle: 0.35486932287327916\n"
     ]
    }
   ],
   "source": [
    "print(f'gbm_pred.shape: {gbm_pred.shape}   gbm_actual.shape: {gbm_actual.shape}   gbm_rmsle: {gbm_rmsle}')\n",
    "#all_df[gbm_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7573415913737139\n",
      "0.7573482277604396\n",
      "0.7573638726800442\n",
      "0.7573743695595399\n",
      "0.7573816347747886\n",
      "0.7573868188567475\n",
      "0.7573934098317713\n",
      "0.7573445165436979\n",
      "0.757319720512726\n",
      "0.7572997017632196\n",
      "0.7573105039805523\n",
      "0.7574431760318319\n",
      "0.7574461700370044\n",
      "0.7574412639552606\n",
      "0.7574411404112728\n",
      "0.7574989219361118\n",
      "0.7575311107182714\n",
      "0.7575482221500504\n",
      "0.757561693315369\n",
      "0.7576396726603499\n"
     ]
    }
   ],
   "source": [
    "params = np.arange(9,11,0.1)\n",
    "best_score_ridge = 10\n",
    "best_alpha = 0\n",
    "ridge_cols = ['holiday', 'workingday', 'temp', 'atemp', 'humidity', \n",
    "                'windspeed','season_Fall', 'season_Spring','season_Summer', 'season_Winter',\n",
    "                'weather_Good','weather_Normal', 'weather_Bad', 'weather_Worse','hour',\n",
    "                'dow', 'woy','peak',\n",
    "                ]\n",
    "\n",
    "for param in params:\n",
    "    ridge_model = Ridge(alpha=param)\n",
    "    (ridge_pred, ridge_actual, ridge_rmsle) = predict_on_validation_set(ridge_model, ridge_cols)\n",
    "    print(ridge_rmsle)\n",
    "    if ridge_rmsle < best_score_ridge:\n",
    "        best_score_ridge = ridge_rmsle\n",
    "        best_alpha = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge_pred.shape: (2286,)   ridge_actual.shape: (2286,)   ridge_rmsle: 0.7572997017632196  best_alpha: 9.899999999999997\n"
     ]
    }
   ],
   "source": [
    "print(f'ridge_pred.shape: {ridge_pred.shape}   ridge_actual.shape: {ridge_actual.shape}   ridge_rmsle: {best_score_ridge}  best_alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06707406, -0.51102997, -0.0103809 ,  0.08948744, -0.01356978,\n",
       "        0.00222207, -0.10778004, -0.31314663,  0.14035563,  0.28057104,\n",
       "        0.12297324,  0.20351779, -0.32044605, -0.00604497,  0.03818036,\n",
       "        0.02437907, -0.0024273 ,  0.55321335])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.3427378053314973, best_rate: {'i': 0.31, 'j': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# the blend gives a better score on the leaderboard, even though it does not on the validation set\n",
    "best_score = 1\n",
    "for i in np.arange(0, 1, 0.01):\n",
    "    for j in np.arange(0, 1, 0.01):\n",
    "        y_pred = np.round(i*rf_pred + j*ridge_pred + (1-i-j)*gbm_pred)\n",
    "        score = get_rmsle(y_pred,rf_actual)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_rate = {'i':i,'j':j}\n",
    "\n",
    "print(f'best_score: {best_score}, best_rate: {best_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n",
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n",
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n"
     ]
    }
   ],
   "source": [
    "rf_pred = predict_on_test_set(rf_model, rf_cols)\n",
    "gbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n",
    "ridge_model = Ridge(alpha=best_alpha)\n",
    "ridge_pred = predict_on_test_set(ridge_model, ridge_cols)\n",
    "\n",
    "#y_pred = np.round(best_rate*rf_pred + (1-best_rate)*gbm_pred)\n",
    "y_pred = np.round(best_rate['i']*rf_pred + best_rate['j']*ridge_pred + (1-best_rate['i']-best_rate['j'])*gbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" submit_manual_rf_df = test_df[['datetime', 'count']].copy()\\nsubmit_manual_rf_df['count'] = rf_pred\\nsubmit_manual_rf_df.to_csv('output/submit_rf_20211012_1.csv', index=False)\\n\\nsubmit_manual_gbm_df = test_df[['datetime', 'count']].copy()\\nsubmit_manual_gbm_df['count'] = gbm_pred\\nsubmit_manual_gbm_df.to_csv('output/submit_gbm_20211012_1.csv', index=False) \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output predictions for submission\n",
    "submit_manual_blend_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_blend_df['count'] = y_pred\n",
    "submit_manual_blend_df.to_csv('output/submit_manual_blend_20211013_3.csv', index=False)\n",
    "\n",
    "\"\"\" submit_manual_rf_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_rf_df['count'] = rf_pred\n",
    "submit_manual_rf_df.to_csv('output/submit_rf_20211012_1.csv', index=False)\n",
    "\n",
    "submit_manual_gbm_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_gbm_df['count'] = gbm_pred\n",
    "submit_manual_gbm_df.to_csv('output/submit_gbm_20211012_1.csv', index=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>sticky</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat_many</th>\n",
       "      <th>humidity_cat_less</th>\n",
       "      <th>wind_cat</th>\n",
       "      <th>season_name</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "      <th>weather_name</th>\n",
       "      <th>weather_Good</th>\n",
       "      <th>weather_Normal</th>\n",
       "      <th>weather_Bad</th>\n",
       "      <th>weather_Worse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  sticky  temp_cat  \\\n",
       "datetime                                                           \n",
       "2011-01-01 00:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 01:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 02:00:00        312498     0      0       0       1.0   \n",
       "\n",
       "                     humidity_cat_many  humidity_cat_less  wind_cat  \\\n",
       "datetime                                                              \n",
       "2011-01-01 00:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 01:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 02:00:00                8.0                4.0       0.0   \n",
       "\n",
       "                    season_name  season_Fall  season_Spring  season_Summer  \\\n",
       "datetime                                                                     \n",
       "2011-01-01 00:00:00      Spring            0              1              0   \n",
       "2011-01-01 01:00:00      Spring            0              1              0   \n",
       "2011-01-01 02:00:00      Spring            0              1              0   \n",
       "\n",
       "                     season_Winter weather_name  weather_Good  weather_Normal  \\\n",
       "datetime                                                                        \n",
       "2011-01-01 00:00:00              0         Good             1               0   \n",
       "2011-01-01 01:00:00              0         Good             1               0   \n",
       "2011-01-01 02:00:00              0         Good             1               0   \n",
       "\n",
       "                     weather_Bad  weather_Worse  \n",
       "datetime                                         \n",
       "2011-01-01 00:00:00            0              0  \n",
       "2011-01-01 01:00:00            0              0  \n",
       "2011-01-01 02:00:00            0              0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
