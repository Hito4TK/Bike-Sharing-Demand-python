{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.style.use('bmh')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['data_set'] = 'train'\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df['data_set'] = 'test'\n",
    "# combine train and test data into one df\n",
    "test_df['registered'] = 0\n",
    "test_df['casual'] = 0\n",
    "test_df['count'] = 0\n",
    "\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "# parse datetime colum & add new time related columns\n",
    "dt = pd.DatetimeIndex(all_df['datetime'])\n",
    "all_df.set_index(dt, inplace=True)\n",
    "\n",
    "# logarithmic transformation of dependent cols\n",
    "# (adding 1 first so that 0 values don't become -inf)\n",
    "for col in ['casual', 'registered', 'count']:\n",
    "    all_df[f'{col}_log'] = np.log(all_df[col] + 1)\n",
    "\n",
    "all_df['date'] = dt.date # yyyymmdd\n",
    "all_df['day'] = dt.day # dd\n",
    "all_df['month'] = dt.month # mm\n",
    "all_df['year'] = dt.year # yyyy\n",
    "all_df['hour'] = dt.hour # hh\n",
    "all_df['dow'] = dt.dayofweek #曜日 Mon:0 Tue:1 Wed:2 Thu:3 Fri:4 Sat:5 Sun:6\n",
    "all_df['woy'] = dt.isocalendar().week #その日の週が年間で見ると何番目の週かを表す数字 [dt.weekofyear]は deprecated\n",
    "\n",
    "# add a count_season column using join\n",
    "by_season = all_df[all_df['data_set'] == 'train'].copy().groupby(['season'])[['count']].agg(sum)\n",
    "by_season.columns = ['count_season']\n",
    "all_df = all_df.join(by_season, on='season')\n",
    "\n",
    "\n",
    "# feature engineer a new column whether its a peak hour or not\n",
    "all_df['peak'] = all_df[['hour', 'workingday']]\\\n",
    "    .apply(lambda df: 3 if ((df['workingday'] == 1 and (df['hour'] == 8 or 17 <= df['hour'] <= 18)) \\\n",
    "                            or (df['workingday'] == 0 and 11 <= df['hour'] <= 17)) else \\\n",
    "                            ( 2 if ((df['workingday'] == 1 and (df['hour'] == 7 or df['hour'] == 9 or df['hour'] == 16 or 19 <= df['hour'] <= 20)) \\\n",
    "                            or (df['workingday'] == 0 and (df['hour'] == 10 or 18 <= df['hour'] <= 19))) else \\\n",
    "                            ( 1 if ((df['workingday'] == 1 and (10 <= df['hour'] <= 15 or 21 <= df['hour'] <= 22)) \\\n",
    "                            or (df['workingday'] == 0 and (8 <= df['hour'] <= 9 or 20 <= df['hour'] <= 23))) else 0)), axis = 1)\n",
    "\n",
    "#ここの修正の仕方は、間違っているので要修正！\n",
    "# sandy\n",
    "#all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "#    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else 0, axis = 1)\n",
    "# 修正後↓\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else df['holiday'], axis = 1)\n",
    "\n",
    "\n",
    "# christmas and others\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday']]\\\n",
    "    .apply(lambda df: 1 if (df['month'] == 12 and df['day'] in [24, 26, 31]) else df['holiday'], axis = 1)\n",
    "all_df['workingday'] = all_df[['month', 'day', 'workingday']]\\\n",
    "    .apply(lambda df: 0 if df['month'] == 12 and df['day'] in [24, 31] else df['workingday'], axis = 1)\n",
    "# これは流石に気づかない気がする。。。気づけない気がする。。。\n",
    "def get_day(day_start):\n",
    "    day_end = day_start + pd.offsets.DateOffset(hours=23)\n",
    "    return pd.date_range(day_start, day_end, freq=\"H\")\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"workingday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"workingday\"] = 1\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"workingday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"workingday\"] = 0\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"holiday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"holiday\"] = 0\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"holiday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"holiday\"] = 1\n",
    "\n",
    "#storms\n",
    "all_df.loc[get_day(datetime(2012, 5, 21)), \"holiday\"] = 1\n",
    "\n",
    "#tornado\n",
    "all_df.loc[get_day(datetime(2012, 6, 1)), \"holiday\"] = 1\n",
    "# from histogram\n",
    "all_df['ideal'] = all_df[['temp', 'windspeed']]\\\n",
    "    .apply(lambda df: 1 if (df['temp'] > 27 and df['windspeed'] < 30) else 0, axis = 1)\n",
    "    \n",
    "all_df['sticky'] = all_df[['humidity', 'workingday']]\\\n",
    "    .apply(lambda df: 1 if (df['workingday'] == 1 and df['humidity'] >= 60) else 0, axis = 1)\n",
    "\n",
    "# temperature\n",
    "all_df.loc[all_df['temp'] < 10,'temp_cat'] = 1\n",
    "all_df.loc[(all_df['temp'] >= 10) & (all_df['temp'] < 15),'temp_cat'] = 2\n",
    "all_df.loc[(all_df['temp'] >= 15) & (all_df['temp'] < 20),'temp_cat'] = 3\n",
    "all_df.loc[(all_df['temp'] >= 20) & (all_df['temp'] < 25),'temp_cat'] = 4\n",
    "all_df.loc[(all_df['temp'] >= 25) & (all_df['temp'] < 30),'temp_cat'] = 5\n",
    "all_df.loc[(all_df['temp'] >= 30) & (all_df['temp'] < 35),'temp_cat'] = 6\n",
    "all_df.loc[(all_df['temp'] >= 35),'temp_cat'] = 7\n",
    "\n",
    "# humidity many category\n",
    "all_df.loc[all_df['humidity'] < 10,'humidity_cat_many'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 10) & (all_df['humidity'] < 20),'humidity_cat_many'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 30),'humidity_cat_many'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 30) & (all_df['humidity'] < 40),'humidity_cat_many'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 50),'humidity_cat_many'] = 4\n",
    "all_df.loc[(all_df['humidity'] >= 50) & (all_df['humidity'] < 60),'humidity_cat_many'] = 5\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 70),'humidity_cat_many'] = 6\n",
    "all_df.loc[(all_df['humidity'] >= 70) & (all_df['humidity'] < 80),'humidity_cat_many'] = 7\n",
    "all_df.loc[(all_df['humidity'] >= 80) & (all_df['humidity'] < 90),'humidity_cat_many'] = 8\n",
    "all_df.loc[(all_df['humidity'] >= 90),'humidity_cat_many'] = 9\n",
    "\n",
    "# humidity not many category\n",
    "all_df.loc[all_df['humidity'] < 20,'humidity_cat_less'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 40),'humidity_cat_less'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 60),'humidity_cat_less'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 80),'humidity_cat_less'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 80),'humidity_cat_less'] = 4\n",
    "\n",
    "# windspeed\n",
    "all_df.loc[all_df['windspeed'] < 5,'wind_cat'] = 0\n",
    "all_df.loc[(all_df['windspeed'] >= 5) & (all_df['windspeed'] < 10),'wind_cat'] = 1\n",
    "all_df.loc[(all_df['windspeed'] >= 10) & (all_df['windspeed'] < 15),'wind_cat'] = 2\n",
    "all_df.loc[(all_df['windspeed'] >= 15) & (all_df['windspeed'] < 20),'wind_cat'] = 3\n",
    "all_df.loc[(all_df['windspeed'] >= 20) & (all_df['windspeed'] < 25),'wind_cat'] = 4\n",
    "all_df.loc[(all_df['windspeed'] >= 25) & (all_df['windspeed'] < 30),'wind_cat'] = 5\n",
    "all_df.loc[(all_df['windspeed'] >= 30) & (all_df['windspeed'] < 35),'wind_cat'] = 6\n",
    "all_df.loc[(all_df['windspeed'] >= 35) & (all_df['windspeed'] < 40),'wind_cat'] = 7\n",
    "all_df.loc[(all_df['windspeed'] >= 40) & (all_df['windspeed'] < 45),'wind_cat'] = 8\n",
    "all_df.loc[(all_df['windspeed'] >= 45),'wind_cat'] = 9\n",
    "\n",
    "# One-hot-Encoding for season\n",
    "season_map = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}\n",
    "all_df['season_name'] = all_df['season'].map(lambda d : season_map[d])\n",
    "temporary = pd.get_dummies(all_df['season_name'])\n",
    "all_df['season_Fall'] = temporary['Fall']\n",
    "all_df['season_Spring'] = temporary['Spring']\n",
    "all_df['season_Summer'] = temporary['Summer']\n",
    "all_df['season_Winter'] = temporary['Winter']\n",
    "\n",
    "# One-hot-Encoding for weather\n",
    "weather_map = {1:'Good', 2:'Normal', 3:'Bad', 4:'Worse'}\n",
    "all_df['weather_name'] = all_df['weather'].map(lambda d : weather_map[d])\n",
    "temporary = pd.get_dummies(all_df['weather_name'])\n",
    "all_df['weather_Good'] = temporary['Good']\n",
    "all_df['weather_Normal'] = temporary['Normal']\n",
    "all_df['weather_Bad'] = temporary['Bad']\n",
    "all_df['weather_Worse'] = temporary['Worse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>sticky</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat_many</th>\n",
       "      <th>humidity_cat_less</th>\n",
       "      <th>wind_cat</th>\n",
       "      <th>season_name</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "      <th>weather_name</th>\n",
       "      <th>weather_Good</th>\n",
       "      <th>weather_Normal</th>\n",
       "      <th>weather_Bad</th>\n",
       "      <th>weather_Worse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  sticky  temp_cat  \\\n",
       "datetime                                                           \n",
       "2011-01-01 00:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 01:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 02:00:00        312498     0      0       0       1.0   \n",
       "\n",
       "                     humidity_cat_many  humidity_cat_less  wind_cat  \\\n",
       "datetime                                                              \n",
       "2011-01-01 00:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 01:00:00                8.0                4.0       0.0   \n",
       "2011-01-01 02:00:00                8.0                4.0       0.0   \n",
       "\n",
       "                    season_name  season_Fall  season_Spring  season_Summer  \\\n",
       "datetime                                                                     \n",
       "2011-01-01 00:00:00      Spring            0              1              0   \n",
       "2011-01-01 01:00:00      Spring            0              1              0   \n",
       "2011-01-01 02:00:00      Spring            0              1              0   \n",
       "\n",
       "                     season_Winter weather_name  weather_Good  weather_Normal  \\\n",
       "datetime                                                                        \n",
       "2011-01-01 00:00:00              0         Good             1               0   \n",
       "2011-01-01 01:00:00              0         Good             1               0   \n",
       "2011-01-01 02:00:00              0         Good             1               0   \n",
       "\n",
       "                     weather_Bad  weather_Worse  \n",
       "datetime                                         \n",
       "2011-01-01 00:00:00            0              0  \n",
       "2011-01-01 01:00:00            0              0  \n",
       "2011-01-01 02:00:00            0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of randomly splitting our training data \n",
    "# for cross validation, let's construct a framework that's more\n",
    "# in line with how the data is divvied up for this competition\n",
    "# (given first 19 days of each month, what is demand for remaining days)\n",
    "# so, let's split our training data into 2 time contiguous datasets\n",
    "# for fitting and validating our model (days 1-14 vs. days 15-19).\n",
    "\n",
    "# also, since submissions are evaluated based on the\n",
    "# root mean squared logarithmic error (RMSLE), let's replicate\n",
    "# that computation as we test and tune our model.\n",
    "\n",
    "train_df = all_df[all_df['data_set'] == 'train']\n",
    "test_df = all_df[all_df['data_set'] == 'test']\n",
    "\n",
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def custom_train_valid_split(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    valid = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def prep_train_data(data, input_cols):\n",
    "    X = data[input_cols].values\n",
    "    y_r = data['registered_log'].values\n",
    "    y_c = data['casual_log'].values\n",
    "\n",
    "    return X, y_r, y_c\n",
    "\n",
    "# predict on validation set & transform output back from log scale\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    \n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, input_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, input_cols)\n",
    "\n",
    "            # training and validating\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "    \n",
    "    rmsle = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    \n",
    "    return (np.array(y_pred_comb_l), np.array(y_actual_comb_l), rmsle)\n",
    "\n",
    "\n",
    "# predict on test set & transform output back from log scale\n",
    "def predict_on_test_set(model, input_cols):\n",
    "    \n",
    "    y_pred_comb_l = []\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "            \n",
    "            # prepare training set\n",
    "            print(f'Now,{year_val} {month_val} testing...')\n",
    "            train_df_tmp = train_df.query('year <= @year_val and month <= @month_val')\n",
    "            test_df_tmp = test_df.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_df_tmp, input_cols)\n",
    "\n",
    "            # prepare testing set\n",
    "            X_test = test_df_tmp[input_cols].values\n",
    "            \n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_test)) - 1\n",
    "            \n",
    "            # add casual & registered predictions together\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "    \n",
    "    return np.array(y_pred_comb_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:13:17,619]\u001b[0m A new study created in memory with name: no-name-18479608-9238-4638-a3de-61d7e3674d74\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:16:42,485]\u001b[0m Trial 0 finished with value: 0.4085897977221024 and parameters: {'reg_alpha': 0.0013292918943162175, 'reg_lambda': 0.07114476009343425, 'num_leaves': 5, 'colsample_bytree': 0.759195090518222, 'subsample': 0.4936111842654619, 'subsample_freq': 1, 'min_child_samples': 0}. Best is trial 0 with value: 0.4085897977221024.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:19:14,515]\u001b[0m Trial 1 finished with value: 0.390863464603388 and parameters: {'reg_alpha': 0.0396760507705299, 'reg_lambda': 0.006358358856676255, 'num_leaves': 5, 'colsample_bytree': 0.41235069657748147, 'subsample': 0.9819459112971965, 'subsample_freq': 6, 'min_child_samples': 2}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適パラメータ {'reg_alpha': 0.0396760507705299, 'reg_lambda': 0.006358358856676255, 'num_leaves': 5, 'colsample_bytree': 0.41235069657748147, 'subsample': 0.9819459112971965, 'subsample_freq': 6, 'min_child_samples': 2}\n",
      "スコア 0.390863464603388\n",
      "所要時間356.89983224868774秒\n"
     ]
    }
   ],
   "source": [
    "# LightGBM with Oputuna for training and validating\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "seed = 42\n",
    "# モデル作成\n",
    "model_r = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "model_c = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "\n",
    "\n",
    "# 学習時fitパラメータ指定\n",
    "\"\"\" fit_params = {'verbose': 0,  # 学習中のコマンドライン出力\n",
    "              'early_stopping_rounds': 10,  # 学習時、評価指標がこの回数連続で改善しなくなった時点でストップ\n",
    "              'eval_metric': 'rmse',  # early_stopping_roundsの評価指標\n",
    "              'eval_set': [(X, y)]  # early_stopping_roundsの評価指標算出用データ\n",
    "              }\n",
    " \"\"\"\n",
    "req_cols = ['season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed', \n",
    "        'day','month', 'year', 'hour', 'dow', 'woy', 'peak', 'ideal',\n",
    "       'sticky', 'temp_cat', 'humidity_cat_many', 'humidity_cat_less','wind_cat'\n",
    "       #'datetime', 'casual', 'registered', 'count','data_set', 'casual_log', 'registered_log', 'count_log', 'date','count_season', \n",
    "       ]\n",
    "\n",
    "start = time.time()\n",
    "# ベイズ最適化時の評価指標算出メソッド\n",
    "def bayes_objective(trial):\n",
    "    params = {\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 0.1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 6),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 10)\n",
    "    }\n",
    "    # モデルにパラメータ適用\n",
    "    model_r.set_params(**params)\n",
    "    model_c.set_params(**params)\n",
    "    \n",
    "    # cross_val_scoreでクロスバリデーション\n",
    "    \n",
    "\n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, req_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, req_cols)\n",
    "\n",
    "            model_r.fit(X_train,y_train_r,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_r)])\n",
    "            model_c.fit(X_train,y_train_c,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_c)])\n",
    "\n",
    "            # training and validating\n",
    "            #model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            #model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "        \n",
    "    rmsle_lgb = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    return rmsle_lgb\n",
    "\n",
    "# ベイズ最適化を実行\n",
    "study = optuna.create_study(direction='minimize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study.optimize(bayes_objective, n_trials=2)#400)\n",
    "\n",
    "# 最適パラメータの表示と保持\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_trial.value\n",
    "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
    "print(f'所要時間{time.time() - start}秒')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "rf_cols = [\n",
    "    #'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'weather', 'temp_cat', 'wind_cat',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    #'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak'\n",
    "    ]\n",
    "\n",
    "(rf_pred, rf_actual, rf_rmsle) = predict_on_validation_set(rf_model, rf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_pred.shape: (2286,)   rf_actual.shape: (2286,)   rf_rmsle: 0.4155804886847993\n"
     ]
    }
   ],
   "source": [
    "print(f'rf_pred.shape: {rf_pred.shape}   rf_actual.shape: {rf_actual.shape}   rf_rmsle: {rf_rmsle}')\n",
    "#all_df[rf_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    #'holiday', 'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "    'hour', 'dow', 'year', 'ideal', #'count_season',\n",
    "]\n",
    "\n",
    "(gbm_pred, gbm_actual, gbm_rmsle) = predict_on_validation_set(gbm_model, gbm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm_pred.shape: (2286,)   gbm_actual.shape: (2286,)   gbm_rmsle: 0.35486932287327916\n"
     ]
    }
   ],
   "source": [
    "print(f'gbm_pred.shape: {gbm_pred.shape}   gbm_actual.shape: {gbm_actual.shape}   gbm_rmsle: {gbm_rmsle}')\n",
    "#all_df[gbm_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.34493980274596825, best_rate: 0.25\n"
     ]
    }
   ],
   "source": [
    "# the blend gives a better score on the leaderboard, even though it does not on the validation set\n",
    "best_score = 1\n",
    "for i in np.arange(0, 1, 0.01):\n",
    "    y_pred = np.round(i*rf_pred + (1-i)*gbm_pred)\n",
    "    score = get_rmsle(y_pred, rf_actual)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_rate = i\n",
    "\n",
    "print(f'best_score: {best_score}, best_rate: {best_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n",
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n"
     ]
    }
   ],
   "source": [
    "rf_pred = predict_on_test_set(rf_model, rf_cols)\n",
    "gbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n",
    "\n",
    "y_pred = np.round(best_rate*rf_pred + (1-best_rate)*gbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" submit_manual_rf_df = test_df[['datetime', 'count']].copy()\\nsubmit_manual_rf_df['count'] = rf_pred\\nsubmit_manual_rf_df.to_csv('output/submit_rf_20211012_1.csv', index=False)\\n\\nsubmit_manual_gbm_df = test_df[['datetime', 'count']].copy()\\nsubmit_manual_gbm_df['count'] = gbm_pred\\nsubmit_manual_gbm_df.to_csv('output/submit_gbm_20211012_1.csv', index=False) \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output predictions for submission\n",
    "submit_manual_blend_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_blend_df['count'] = y_pred\n",
    "submit_manual_blend_df.to_csv('output/submit_manual_blend_20211013_1.csv', index=False)\n",
    "\n",
    "\"\"\" submit_manual_rf_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_rf_df['count'] = rf_pred\n",
    "submit_manual_rf_df.to_csv('output/submit_rf_20211012_1.csv', index=False)\n",
    "\n",
    "submit_manual_gbm_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_gbm_df['count'] = gbm_pred\n",
    "submit_manual_gbm_df.to_csv('output/submit_gbm_20211012_1.csv', index=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0 RandomForestRegressor\n",
    "rf_params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "rf_cols = [\n",
    "    'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak'\n",
    "    ]\n",
    "# Level 0 GradientBoostingRegressor\n",
    "gbm_params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**gbm_params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    'hour', 'dow', 'year', 'ideal', 'count_season',\n",
    "]\n",
    "clf_input_cols = [rf_cols, gbm_cols]\n",
    "clfs = [rf_model, gbm_model]\n",
    "# Create train and test sets for blending and Pre-allocate the data\n",
    "blend_train = np.zeros((train_df.shape[0], len(clfs)))\n",
    "blend_test = np.zeros((test_df.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each classifier, we train the classifier with its corresponding input_cols \n",
    "# and record the predictions on the train and the test set\n",
    "for clf_index, (input_cols, clf) in enumerate(zip(clf_input_cols, clfs)):\n",
    "    \n",
    "    # prepare training and validation set\n",
    "    X_train, y_train_r, y_train_c = prep_train_data(train_df, input_cols)\n",
    "    \n",
    "    # prepare testing set\n",
    "    X_test = test_df[input_cols].values\n",
    "    \n",
    "    model_r = clf.fit(X_train, y_train_r)\n",
    "    y_pred_train_r = np.exp(model_r.predict(X_train)) - 1\n",
    "    y_pred_test_r = np.exp(model_r.predict(X_test)) - 1\n",
    "\n",
    "    model_c = clf.fit(X_train, y_train_c)\n",
    "    y_pred_train_c = np.exp(model_c.predict(X_train)) - 1\n",
    "    y_pred_test_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "    y_pred_train_comb = np.round(y_pred_train_r + y_pred_train_c)\n",
    "    y_pred_train_comb[y_pred_train_comb < 0] = 0\n",
    "    \n",
    "    y_pred_test_comb = np.round(y_pred_test_r + y_pred_test_c)\n",
    "    y_pred_test_comb[y_pred_test_comb < 0] = 0\n",
    "    \n",
    "    blend_train[:, clf_index] = y_pred_train_comb\n",
    "    blend_test[:, clf_index] = y_pred_test_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38011939 0.66365917]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9676364408685162"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level 1 Belending Classifier using LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "bclf = LinearRegression(fit_intercept=False)\n",
    "bclf.fit(blend_train, train_df['count'])\n",
    "# What is the weighted combination of the base classifiers?\n",
    "print(bclf.coef_)\n",
    "# Stacked and Blending predictions\n",
    "y_pred_blend = np.round(bclf.predict(blend_test))\n",
    "# R^2 score\n",
    "bclf.score(blend_train, train_df['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predictions for submission\n",
    "submit_stack_blend_df = test_df[['datetime', 'count']].copy()\n",
    "submit_stack_blend_df['count'] = y_pred_blend\n",
    "submit_stack_blend_df.to_csv('output/submit_stack_blend_20211012_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>sticky</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat</th>\n",
       "      <th>wind_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  sticky  temp_cat  \\\n",
       "datetime                                                           \n",
       "2011-01-01 00:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 01:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 02:00:00        312498     0      0       0       1.0   \n",
       "\n",
       "                     humidity_cat  wind_cat  \n",
       "datetime                                     \n",
       "2011-01-01 00:00:00           4.0       0.0  \n",
       "2011-01-01 01:00:00           4.0       0.0  \n",
       "2011-01-01 02:00:00           4.0       0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
