{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.style.use('bmh')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['data_set'] = 'train'\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df['data_set'] = 'test'\n",
    "# combine train and test data into one df\n",
    "test_df['registered'] = 0\n",
    "test_df['casual'] = 0\n",
    "test_df['count'] = 0\n",
    "\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "# parse datetime colum & add new time related columns\n",
    "dt = pd.DatetimeIndex(all_df['datetime'])\n",
    "all_df.set_index(dt, inplace=True)\n",
    "\n",
    "# logarithmic transformation of dependent cols\n",
    "# (adding 1 first so that 0 values don't become -inf)\n",
    "for col in ['casual', 'registered', 'count']:\n",
    "    all_df[f'{col}_log'] = np.log(all_df[col] + 1)\n",
    "\n",
    "all_df['date'] = dt.date # yyyymmdd\n",
    "all_df['day'] = dt.day # dd\n",
    "all_df['month'] = dt.month # mm\n",
    "all_df['year'] = dt.year # yyyy\n",
    "all_df['hour'] = dt.hour # hh\n",
    "all_df['dow'] = dt.dayofweek #曜日 Mon:0 Tue:1 Wed:2 Thu:3 Fri:4 Sat:5 Sun:6\n",
    "all_df['woy'] = dt.isocalendar().week #その日の週が年間で見ると何番目の週かを表す数字 [dt.weekofyear]は deprecated\n",
    "\n",
    "# add a count_season column using join\n",
    "by_season = all_df[all_df['data_set'] == 'train'].copy().groupby(['season'])[['count']].agg(sum)\n",
    "by_season.columns = ['count_season']\n",
    "all_df = all_df.join(by_season, on='season')\n",
    "\n",
    "\n",
    "# feature engineer a new column whether its a peak hour or not\n",
    "all_df['peak'] = all_df[['hour', 'workingday']]\\\n",
    "    .apply(lambda df: 3 if ((df['workingday'] == 1 and (df['hour'] == 8 or 17 <= df['hour'] <= 18)) \\\n",
    "                            or (df['workingday'] == 0 and 11 <= df['hour'] <= 17)) else \\\n",
    "                            ( 2 if ((df['workingday'] == 1 and (df['hour'] == 7 or df['hour'] == 9 or df['hour'] == 16 or 19 <= df['hour'] <= 20)) \\\n",
    "                            or (df['workingday'] == 0 and (df['hour'] == 10 or 18 <= df['hour'] <= 19))) else \\\n",
    "                            ( 1 if ((df['workingday'] == 1 and (10 <= df['hour'] <= 15 or 21 <= df['hour'] <= 22)) \\\n",
    "                            or (df['workingday'] == 0 and (8 <= df['hour'] <= 9 or 20 <= df['hour'] <= 23))) else 0)), axis = 1)\n",
    "\n",
    "#ここの修正の仕方は、間違っているので要修正！\n",
    "# sandy\n",
    "#all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "#    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else 0, axis = 1)\n",
    "# 修正後↓\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else df['holiday'], axis = 1)\n",
    "\n",
    "\n",
    "# christmas and others\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday']]\\\n",
    "    .apply(lambda df: 1 if (df['month'] == 12 and df['day'] in [24, 26, 31]) else df['holiday'], axis = 1)\n",
    "all_df['workingday'] = all_df[['month', 'day', 'workingday']]\\\n",
    "    .apply(lambda df: 0 if df['month'] == 12 and df['day'] in [24, 31] else df['workingday'], axis = 1)\n",
    "# これは流石に気づかない気がする。。。気づけない気がする。。。\n",
    "def get_day(day_start):\n",
    "    day_end = day_start + pd.offsets.DateOffset(hours=23)\n",
    "    return pd.date_range(day_start, day_end, freq=\"H\")\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"workingday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"workingday\"] = 1\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"workingday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"workingday\"] = 0\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"holiday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"holiday\"] = 0\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"holiday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"holiday\"] = 1\n",
    "\n",
    "#storms\n",
    "all_df.loc[get_day(datetime(2012, 5, 21)), \"holiday\"] = 1\n",
    "\n",
    "#tornado\n",
    "all_df.loc[get_day(datetime(2012, 6, 1)), \"holiday\"] = 1\n",
    "# from histogram\n",
    "all_df['ideal'] = all_df[['temp', 'windspeed']]\\\n",
    "    .apply(lambda df: 1 if (df['temp'] > 27 and df['windspeed'] < 30) else 0, axis = 1)\n",
    "    \n",
    "all_df['sticky'] = all_df[['humidity', 'workingday']]\\\n",
    "    .apply(lambda df: 1 if (df['workingday'] == 1 and df['humidity'] >= 60) else 0, axis = 1)\n",
    "\n",
    "# One-hot-Encoding for season\n",
    "#season_map = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}\n",
    "#all_df['season'] = all_df['season'].map(lambda d : season_map[d])\n",
    "#temporary = pd.get_dummies(all_df['season'])\n",
    "#all_df['season_Fall'] = temporary['Fall']\n",
    "#all_df['season_Spring'] = temporary['Spring']\n",
    "#all_df['season_Summer'] = temporary['Summer']\n",
    "#all_df['season_Winter'] = temporary['Winter']\n",
    "\n",
    "# temperature\n",
    "all_df.loc[all_df['temp'] < 10,'temp_cat'] = 1\n",
    "all_df.loc[(all_df['temp'] >= 10) & (all_df['temp'] < 15),'temp_cat'] = 2\n",
    "all_df.loc[(all_df['temp'] >= 15) & (all_df['temp'] < 20),'temp_cat'] = 3\n",
    "all_df.loc[(all_df['temp'] >= 20) & (all_df['temp'] < 25),'temp_cat'] = 4\n",
    "all_df.loc[(all_df['temp'] >= 25) & (all_df['temp'] < 30),'temp_cat'] = 5\n",
    "all_df.loc[(all_df['temp'] >= 30) & (all_df['temp'] < 35),'temp_cat'] = 6\n",
    "all_df.loc[(all_df['temp'] >= 35),'temp_cat'] = 7\n",
    "\n",
    "# humidity many category\n",
    "all_df.loc[all_df['humidity'] < 10,'humidity_cat_many'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 10) & (all_df['humidity'] < 20),'humidity_cat_many'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 30),'humidity_cat_many'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 30) & (all_df['humidity'] < 40),'humidity_cat_many'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 50),'humidity_cat_many'] = 4\n",
    "all_df.loc[(all_df['humidity'] >= 50) & (all_df['humidity'] < 60),'humidity_cat_many'] = 5\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 70),'humidity_cat_many'] = 6\n",
    "all_df.loc[(all_df['humidity'] >= 70) & (all_df['humidity'] < 80),'humidity_cat_many'] = 7\n",
    "all_df.loc[(all_df['humidity'] >= 80) & (all_df['humidity'] < 90),'humidity_cat_many'] = 8\n",
    "all_df.loc[(all_df['humidity'] >= 90),'humidity_cat_many'] = 9\n",
    "\n",
    "# humidity not many category\n",
    "all_df.loc[all_df['humidity'] < 20,'humidity_cat_less'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 40),'humidity_cat_less'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 60),'humidity_cat_less'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 80),'humidity_cat_less'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 80),'humidity_cat_less'] = 4\n",
    "\n",
    "# windspeed\n",
    "all_df.loc[all_df['windspeed'] < 5,'wind_cat'] = 0\n",
    "all_df.loc[(all_df['windspeed'] >= 5) & (all_df['windspeed'] < 10),'wind_cat'] = 1\n",
    "all_df.loc[(all_df['windspeed'] >= 10) & (all_df['windspeed'] < 15),'wind_cat'] = 2\n",
    "all_df.loc[(all_df['windspeed'] >= 15) & (all_df['windspeed'] < 20),'wind_cat'] = 3\n",
    "all_df.loc[(all_df['windspeed'] >= 20) & (all_df['windspeed'] < 25),'wind_cat'] = 4\n",
    "all_df.loc[(all_df['windspeed'] >= 25) & (all_df['windspeed'] < 30),'wind_cat'] = 5\n",
    "all_df.loc[(all_df['windspeed'] >= 30) & (all_df['windspeed'] < 35),'wind_cat'] = 6\n",
    "all_df.loc[(all_df['windspeed'] >= 35) & (all_df['windspeed'] < 40),'wind_cat'] = 7\n",
    "all_df.loc[(all_df['windspeed'] >= 40) & (all_df['windspeed'] < 45),'wind_cat'] = 8\n",
    "all_df.loc[(all_df['windspeed'] >= 45),'wind_cat'] = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of randomly splitting our training data \n",
    "# for cross validation, let's construct a framework that's more\n",
    "# in line with how the data is divvied up for this competition\n",
    "# (given first 19 days of each month, what is demand for remaining days)\n",
    "# so, let's split our training data into 2 time contiguous datasets\n",
    "# for fitting and validating our model (days 1-14 vs. days 15-19).\n",
    "\n",
    "# also, since submissions are evaluated based on the\n",
    "# root mean squared logarithmic error (RMSLE), let's replicate\n",
    "# that computation as we test and tune our model.\n",
    "\n",
    "train_df = all_df[all_df['data_set'] == 'train']\n",
    "test_df = all_df[all_df['data_set'] == 'test']\n",
    "\n",
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def custom_train_valid_split(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    valid = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def prep_train_data(data, input_cols):\n",
    "    X = data[input_cols].values\n",
    "    y_r = data['registered_log'].values\n",
    "    y_c = data['casual_log'].values\n",
    "\n",
    "    return X, y_r, y_c\n",
    "\n",
    "# predict on validation set & transform output back from log scale\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    \n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, input_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, input_cols)\n",
    "\n",
    "            # training and validating\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "    \n",
    "    rmsle = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    \n",
    "    return (np.array(y_pred_comb_l), np.array(y_actual_comb_l), rmsle)\n",
    "\n",
    "\n",
    "# predict on test set & transform output back from log scale\n",
    "def predict_on_test_set(model, input_cols):\n",
    "    \n",
    "    y_pred_comb_l = []\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "            \n",
    "            # prepare training set\n",
    "            print(f'Now,{year_val} {month_val} testing...')\n",
    "            train_df_tmp = train_df.query('year <= @year_val and month <= @month_val')\n",
    "            test_df_tmp = test_df.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_df_tmp, input_cols)\n",
    "\n",
    "            # prepare testing set\n",
    "            X_test = test_df_tmp[input_cols].values\n",
    "            \n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_test)) - 1\n",
    "            \n",
    "            # add casual & registered predictions together\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "    \n",
    "    return np.array(y_pred_comb_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:13:03,071]\u001b[0m A new study created in memory with name: no-name-1a126be7-7223-4175-b279-08f6aa93a803\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:16:42,757]\u001b[0m Trial 0 finished with value: 0.4085897977221024 and parameters: {'reg_alpha': 0.0013292918943162175, 'reg_lambda': 0.07114476009343425, 'num_leaves': 5, 'colsample_bytree': 0.759195090518222, 'subsample': 0.4936111842654619, 'subsample_freq': 1, 'min_child_samples': 0}. Best is trial 0 with value: 0.4085897977221024.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:19:54,527]\u001b[0m Trial 1 finished with value: 0.390863464603388 and parameters: {'reg_alpha': 0.0396760507705299, 'reg_lambda': 0.006358358856676255, 'num_leaves': 5, 'colsample_bytree': 0.41235069657748147, 'subsample': 0.9819459112971965, 'subsample_freq': 6, 'min_child_samples': 2}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:22:17,244]\u001b[0m Trial 2 finished with value: 0.40907103197549827 and parameters: {'reg_alpha': 0.0003511356313970409, 'reg_lambda': 0.0003549878832196505, 'num_leaves': 3, 'colsample_bytree': 0.7148538589793427, 'subsample': 0.6591670111852694, 'subsample_freq': 2, 'min_child_samples': 6}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:24:38,644]\u001b[0m Trial 3 finished with value: 0.39458028535022166 and parameters: {'reg_alpha': 0.00026210878782654407, 'reg_lambda': 0.0007523742884534858, 'num_leaves': 3, 'colsample_bytree': 0.6736419905302216, 'subsample': 0.8711055768358081, 'subsample_freq': 1, 'min_child_samples': 5}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:27:17,996]\u001b[0m Trial 4 finished with value: 0.4133063887541459 and parameters: {'reg_alpha': 0.005987474910461402, 'reg_lambda': 0.000137832374550072, 'num_leaves': 5, 'colsample_bytree': 0.502314474212375, 'subsample': 0.43903095579116774, 'subsample_freq': 7, 'min_child_samples': 10}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:28:55,597]\u001b[0m Trial 5 finished with value: 0.5247145745683431 and parameters: {'reg_alpha': 0.026619018884890575, 'reg_lambda': 0.0008200518402245837, 'num_leaves': 2, 'colsample_bytree': 0.8105398159072941, 'subsample': 0.6640914962437607, 'subsample_freq': 0, 'min_child_samples': 5}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:31:02,523]\u001b[0m Trial 6 finished with value: 0.4112698843985139 and parameters: {'reg_alpha': 0.00012681352169084607, 'reg_lambda': 0.053451661106468214, 'num_leaves': 3, 'colsample_bytree': 0.7975133706123891, 'subsample': 0.5870266456536466, 'subsample_freq': 4, 'min_child_samples': 6}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:33:52,419]\u001b[0m Trial 7 finished with value: 0.39483301238867446 and parameters: {'reg_alpha': 0.00035856126103454, 'reg_lambda': 0.08105016126411585, 'num_leaves': 5, 'colsample_bytree': 0.9636993649385135, 'subsample': 0.9368964102565893, 'subsample_freq': 4, 'min_child_samples': 10}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:36:01,350]\u001b[0m Trial 8 finished with value: 0.5369793657172212 and parameters: {'reg_alpha': 0.00018427970406864567, 'reg_lambda': 0.0003872118032174585, 'num_leaves': 2, 'colsample_bytree': 0.5951981984579586, 'subsample': 0.6332063738136893, 'subsample_freq': 2, 'min_child_samples': 9}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:38:14,557]\u001b[0m Trial 9 finished with value: 0.3912944999442154 and parameters: {'reg_alpha': 0.0011756010900231862, 'reg_lambda': 0.0006963114377829289, 'num_leaves': 4, 'colsample_bytree': 0.4845545349848576, 'subsample': 0.8813181884524238, 'subsample_freq': 0, 'min_child_samples': 10}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:41:01,740]\u001b[0m Trial 10 finished with value: 0.39548561715413383 and parameters: {'reg_alpha': 0.08640428845952951, 'reg_lambda': 0.009247015419816046, 'num_leaves': 6, 'colsample_bytree': 0.4107771253688919, 'subsample': 0.791119930466907, 'subsample_freq': 7, 'min_child_samples': 0}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:43:39,334]\u001b[0m Trial 11 finished with value: 0.4051579824245135 and parameters: {'reg_alpha': 0.003159674646953821, 'reg_lambda': 0.004392125319176158, 'num_leaves': 4, 'colsample_bytree': 0.4098234646373848, 'subsample': 0.9674858319842282, 'subsample_freq': 5, 'min_child_samples': 2}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:46:09,188]\u001b[0m Trial 12 finished with value: 0.4003493616291688 and parameters: {'reg_alpha': 0.0146124525614599, 'reg_lambda': 0.009674445793638686, 'num_leaves': 4, 'colsample_bytree': 0.5307121503018024, 'subsample': 0.7998293121457789, 'subsample_freq': 6, 'min_child_samples': 3}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:49:05,261]\u001b[0m Trial 13 finished with value: 0.39135417860644656 and parameters: {'reg_alpha': 0.0010891337991705862, 'reg_lambda': 0.0025475085875100623, 'num_leaves': 6, 'colsample_bytree': 0.5375211666397564, 'subsample': 0.9934047109242902, 'subsample_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:52:06,762]\u001b[0m Trial 14 finished with value: 0.39411782718966937 and parameters: {'reg_alpha': 0.08779247898310383, 'reg_lambda': 0.002342232862163071, 'num_leaves': 5, 'colsample_bytree': 0.4645482374284395, 'subsample': 0.8722012357929033, 'subsample_freq': 5, 'min_child_samples': 3}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:54:15,739]\u001b[0m Trial 15 finished with value: 0.4039283882341731 and parameters: {'reg_alpha': 0.0012518616811333513, 'reg_lambda': 0.019661861660945346, 'num_leaves': 4, 'colsample_bytree': 0.6212939496794336, 'subsample': 0.7828613557642827, 'subsample_freq': 0, 'min_child_samples': 2}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:57:04,614]\u001b[0m Trial 16 finished with value: 0.39676477432349627 and parameters: {'reg_alpha': 0.018602960148434433, 'reg_lambda': 0.0014285771830109776, 'num_leaves': 6, 'colsample_bytree': 0.456750097483722, 'subsample': 0.9069007227177349, 'subsample_freq': 6, 'min_child_samples': 7}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 15:59:48,918]\u001b[0m Trial 17 finished with value: 0.3945647773811982 and parameters: {'reg_alpha': 0.005207363661185508, 'reg_lambda': 0.006442573750936892, 'num_leaves': 5, 'colsample_bytree': 0.5837465543798832, 'subsample': 0.7495065293464199, 'subsample_freq': 3, 'min_child_samples': 4}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:02:12,397]\u001b[0m Trial 18 finished with value: 0.4124457437455004 and parameters: {'reg_alpha': 0.04101868936775286, 'reg_lambda': 0.02495261495555089, 'num_leaves': 4, 'colsample_bytree': 0.9157899251173307, 'subsample': 0.8574472654703091, 'subsample_freq': 5, 'min_child_samples': 1}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:04:20,390]\u001b[0m Trial 19 finished with value: 0.3933377886326141 and parameters: {'reg_alpha': 0.0006728231897704885, 'reg_lambda': 0.00010593498200045963, 'num_leaves': 3, 'colsample_bytree': 0.4745491606995837, 'subsample': 0.9358101528760775, 'subsample_freq': 6, 'min_child_samples': 8}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:07:09,076]\u001b[0m Trial 20 finished with value: 0.3964672134551099 and parameters: {'reg_alpha': 0.0027552894628990686, 'reg_lambda': 0.0003351622688986145, 'num_leaves': 5, 'colsample_bytree': 0.6313454171631775, 'subsample': 0.7303416674801917, 'subsample_freq': 2, 'min_child_samples': 3}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 16:10:30,703]\u001b[0m Trial 21 finished with value: 0.3937332013115787 and parameters: {'reg_alpha': 0.0011150950860431825, 'reg_lambda': 0.0026773644070503303, 'num_leaves': 6, 'colsample_bytree': 0.5370197262532346, 'subsample': 0.9960022811811066, 'subsample_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 0.390863464603388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45203/3602783283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m study = optuna.create_study(direction='minimize',\n\u001b[1;32m     86\u001b[0m                             sampler=optuna.samplers.TPESampler(seed=seed))\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# 最適パラメータの表示と保持\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_45203/3602783283.py\u001b[0m in \u001b[0;36mbayes_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmodel_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mmodel_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# training and validating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     categorical_feature=categorical_feature, callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    686\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m         \"\"\"\n\u001b[0;32m-> 2856\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3384\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3386\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   3387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "seed = 42\n",
    "# モデル作成\n",
    "model_r = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "model_c = LGBMRegressor(boosting_type='gbdt', objective='regression',\n",
    "                      random_state=seed, n_estimators=10000)  # チューニング前のモデル\n",
    "\n",
    "\n",
    "# 学習時fitパラメータ指定\n",
    "\"\"\" fit_params = {'verbose': 0,  # 学習中のコマンドライン出力\n",
    "              'early_stopping_rounds': 10,  # 学習時、評価指標がこの回数連続で改善しなくなった時点でストップ\n",
    "              'eval_metric': 'rmse',  # early_stopping_roundsの評価指標\n",
    "              'eval_set': [(X, y)]  # early_stopping_roundsの評価指標算出用データ\n",
    "              }\n",
    " \"\"\"\n",
    "req_cols = ['season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed', \n",
    "        'day','month', 'year', 'hour', 'dow', 'woy', 'peak', 'ideal',\n",
    "       'sticky', 'temp_cat', 'humidity_cat_many', 'humidity_cat_less','wind_cat'\n",
    "       #'datetime', 'casual', 'registered', 'count','data_set', 'casual_log', 'registered_log', 'count_log', 'date','count_season', \n",
    "       ]\n",
    "\n",
    "start = time.time()\n",
    "# ベイズ最適化時の評価指標算出メソッド\n",
    "def bayes_objective(trial):\n",
    "    params = {\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 0.1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 6),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 10)\n",
    "    }\n",
    "    # モデルにパラメータ適用\n",
    "    model_r.set_params(**params)\n",
    "    model_c.set_params(**params)\n",
    "    \n",
    "    # cross_val_scoreでクロスバリデーション\n",
    "    \n",
    "\n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, req_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, req_cols)\n",
    "\n",
    "            model_r.fit(X_train,y_train_r,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_r)])\n",
    "            model_c.fit(X_train,y_train_c,verbose=0,early_stopping_rounds=10,eval_metric='rmse',eval_set=[(X_train, y_train_c)])\n",
    "\n",
    "            # training and validating\n",
    "            #model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            #model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "        \n",
    "    rmsle_lgb = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    return rmsle_lgb\n",
    "\n",
    "# ベイズ最適化を実行\n",
    "study = optuna.create_study(direction='minimize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study.optimize(bayes_objective, n_trials=400)\n",
    "\n",
    "# 最適パラメータの表示と保持\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_trial.value\n",
    "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
    "print(f'所要時間{time.time() - start}秒')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "rf_cols = [\n",
    "    #'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'weather', 'temp_cat', 'wind_cat',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    #'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak'\n",
    "    ]\n",
    "\n",
    "(rf_pred, rf_actual, rf_rmsle) = predict_on_validation_set(rf_model, rf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_pred.shape: (2286,)   rf_actual.shape: (2286,)   rf_rmsle: 0.4155804886847993\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>wind_cat</th>\n",
       "      <th>workingday</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sticky</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.103713</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>-0.014524</td>\n",
       "      <td>0.026336</td>\n",
       "      <td>0.243523</td>\n",
       "      <td>-0.020203</td>\n",
       "      <td>-0.046424</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>-0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_cat</th>\n",
       "      <td>-0.103713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024995</td>\n",
       "      <td>0.062923</td>\n",
       "      <td>0.302664</td>\n",
       "      <td>-0.068965</td>\n",
       "      <td>-0.014099</td>\n",
       "      <td>0.134049</td>\n",
       "      <td>-0.031761</td>\n",
       "      <td>0.186577</td>\n",
       "      <td>0.139005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_cat</th>\n",
       "      <td>0.024231</td>\n",
       "      <td>-0.024995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.146173</td>\n",
       "      <td>-0.005202</td>\n",
       "      <td>-0.185632</td>\n",
       "      <td>0.138555</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.128262</td>\n",
       "      <td>0.183375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.062923</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>-0.240847</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>-0.698028</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>-0.104563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>-0.014524</td>\n",
       "      <td>0.302664</td>\n",
       "      <td>-0.146173</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032516</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>-0.006117</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>0.814302</td>\n",
       "      <td>-0.007072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.026336</td>\n",
       "      <td>-0.068965</td>\n",
       "      <td>-0.005202</td>\n",
       "      <td>-0.240847</td>\n",
       "      <td>-0.032516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109330</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.169788</td>\n",
       "      <td>0.081117</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sticky</th>\n",
       "      <td>0.243523</td>\n",
       "      <td>-0.014099</td>\n",
       "      <td>-0.185632</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>-0.109330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186289</td>\n",
       "      <td>-0.399949</td>\n",
       "      <td>0.096672</td>\n",
       "      <td>-0.194430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>-0.020203</td>\n",
       "      <td>0.134049</td>\n",
       "      <td>0.138555</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>-0.006117</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.186289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>-0.005437</td>\n",
       "      <td>0.488565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>-0.046424</td>\n",
       "      <td>-0.031761</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.698028</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>-0.169788</td>\n",
       "      <td>-0.399949</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.073942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woy</th>\n",
       "      <td>0.009692</td>\n",
       "      <td>0.186577</td>\n",
       "      <td>-0.128262</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.814302</td>\n",
       "      <td>0.081117</td>\n",
       "      <td>0.096672</td>\n",
       "      <td>-0.005437</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <td>-0.002559</td>\n",
       "      <td>0.139005</td>\n",
       "      <td>0.183375</td>\n",
       "      <td>-0.104563</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>-0.194430</td>\n",
       "      <td>0.488565</td>\n",
       "      <td>0.073942</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             weather  temp_cat  wind_cat  workingday    season   holiday  \\\n",
       "weather     1.000000 -0.103713  0.024231    0.042061 -0.014524  0.026336   \n",
       "temp_cat   -0.103713  1.000000 -0.024995    0.062923  0.302664 -0.068965   \n",
       "wind_cat    0.024231 -0.024995  1.000000   -0.000978 -0.146173 -0.005202   \n",
       "workingday  0.042061  0.062923 -0.000978    1.000000  0.010879 -0.240847   \n",
       "season     -0.014524  0.302664 -0.146173    0.010879  1.000000 -0.032516   \n",
       "holiday     0.026336 -0.068965 -0.005202   -0.240847 -0.032516  1.000000   \n",
       "sticky      0.243523 -0.014099 -0.185632    0.536900  0.095556 -0.109330   \n",
       "hour       -0.020203  0.134049  0.138555    0.002185 -0.006117  0.003451   \n",
       "dow        -0.046424 -0.031761  0.000830   -0.698028 -0.007448 -0.169788   \n",
       "woy         0.009692  0.186577 -0.128262   -0.025700  0.814302  0.081117   \n",
       "peak       -0.002559  0.139005  0.183375   -0.104563 -0.007072  0.021277   \n",
       "\n",
       "              sticky      hour       dow       woy      peak  \n",
       "weather     0.243523 -0.020203 -0.046424  0.009692 -0.002559  \n",
       "temp_cat   -0.014099  0.134049 -0.031761  0.186577  0.139005  \n",
       "wind_cat   -0.185632  0.138555  0.000830 -0.128262  0.183375  \n",
       "workingday  0.536900  0.002185 -0.698028 -0.025700 -0.104563  \n",
       "season      0.095556 -0.006117 -0.007448  0.814302 -0.007072  \n",
       "holiday    -0.109330  0.003451 -0.169788  0.081117  0.021277  \n",
       "sticky      1.000000 -0.186289 -0.399949  0.096672 -0.194430  \n",
       "hour       -0.186289  1.000000 -0.002893 -0.005437  0.488565  \n",
       "dow        -0.399949 -0.002893  1.000000  0.009368  0.073942  \n",
       "woy         0.096672 -0.005437  0.009368  1.000000 -0.003243  \n",
       "peak       -0.194430  0.488565  0.073942 -0.003243  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'rf_pred.shape: {rf_pred.shape}   rf_actual.shape: {rf_actual.shape}   rf_rmsle: {rf_rmsle}')\n",
    "all_df[rf_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 training and validating...\n",
      "Now,2011 2 training and validating...\n",
      "Now,2011 3 training and validating...\n",
      "Now,2011 4 training and validating...\n",
      "Now,2011 5 training and validating...\n",
      "Now,2011 6 training and validating...\n",
      "Now,2011 7 training and validating...\n",
      "Now,2011 8 training and validating...\n",
      "Now,2011 9 training and validating...\n",
      "Now,2011 10 training and validating...\n",
      "Now,2011 11 training and validating...\n",
      "Now,2011 12 training and validating...\n",
      "Now,2012 1 training and validating...\n",
      "Now,2012 2 training and validating...\n",
      "Now,2012 3 training and validating...\n",
      "Now,2012 4 training and validating...\n",
      "Now,2012 5 training and validating...\n",
      "Now,2012 6 training and validating...\n",
      "Now,2012 7 training and validating...\n",
      "Now,2012 8 training and validating...\n",
      "Now,2012 9 training and validating...\n",
      "Now,2012 10 training and validating...\n",
      "Now,2012 11 training and validating...\n",
      "Now,2012 12 training and validating...\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    #'holiday', 'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "    'hour', 'dow', 'year', 'ideal', #'count_season',\n",
    "]\n",
    "\n",
    "(gbm_pred, gbm_actual, gbm_rmsle) = predict_on_validation_set(gbm_model, gbm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm_pred.shape: (2286,)   gbm_actual.shape: (2286,)   gbm_rmsle: 0.35486932287327916\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>season</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.102640</td>\n",
       "      <td>-0.105563</td>\n",
       "      <td>0.418130</td>\n",
       "      <td>0.026226</td>\n",
       "      <td>0.026336</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>-0.014524</td>\n",
       "      <td>-0.020203</td>\n",
       "      <td>-0.046424</td>\n",
       "      <td>-0.019157</td>\n",
       "      <td>-0.145407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>-0.102640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.070342</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.312025</td>\n",
       "      <td>0.137603</td>\n",
       "      <td>-0.036220</td>\n",
       "      <td>0.040913</td>\n",
       "      <td>0.727266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>-0.105563</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051918</td>\n",
       "      <td>-0.062336</td>\n",
       "      <td>-0.072605</td>\n",
       "      <td>0.067594</td>\n",
       "      <td>0.319380</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>-0.038918</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.701874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.418130</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>-0.051918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.290105</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>-0.276498</td>\n",
       "      <td>-0.035233</td>\n",
       "      <td>-0.083546</td>\n",
       "      <td>-0.141678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.026226</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.062336</td>\n",
       "      <td>-0.290105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005298</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>0.137252</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>-0.008740</td>\n",
       "      <td>-0.051489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.026336</td>\n",
       "      <td>-0.070342</td>\n",
       "      <td>-0.072605</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>-0.005298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240847</td>\n",
       "      <td>-0.032516</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.169788</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>-0.022858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.067594</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>-0.240847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>-0.698028</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.023068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>-0.014524</td>\n",
       "      <td>0.312025</td>\n",
       "      <td>0.319380</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>-0.032516</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006117</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>0.156455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>-0.020203</td>\n",
       "      <td>0.137603</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>-0.276498</td>\n",
       "      <td>0.137252</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>-0.006117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>0.113745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>-0.046424</td>\n",
       "      <td>-0.036220</td>\n",
       "      <td>-0.038918</td>\n",
       "      <td>-0.035233</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>-0.169788</td>\n",
       "      <td>-0.698028</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.009208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-0.019157</td>\n",
       "      <td>0.040913</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>-0.083546</td>\n",
       "      <td>-0.008740</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal</th>\n",
       "      <td>-0.145407</td>\n",
       "      <td>0.727266</td>\n",
       "      <td>0.701874</td>\n",
       "      <td>-0.141678</td>\n",
       "      <td>-0.051489</td>\n",
       "      <td>-0.022858</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.156455</td>\n",
       "      <td>0.113745</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             weather      temp     atemp  humidity  windspeed   holiday  \\\n",
       "weather     1.000000 -0.102640 -0.105563  0.418130   0.026226  0.026336   \n",
       "temp       -0.102640  1.000000  0.987672 -0.069881  -0.023125 -0.070342   \n",
       "atemp      -0.105563  0.987672  1.000000 -0.051918  -0.062336 -0.072605   \n",
       "humidity    0.418130 -0.069881 -0.051918  1.000000  -0.290105  0.012676   \n",
       "windspeed   0.026226 -0.023125 -0.062336 -0.290105   1.000000 -0.005298   \n",
       "holiday     0.026336 -0.070342 -0.072605  0.012676  -0.005298  1.000000   \n",
       "workingday  0.042061  0.069153  0.067594  0.014316  -0.001937 -0.240847   \n",
       "season     -0.014524  0.312025  0.319380  0.150625  -0.149773 -0.032516   \n",
       "hour       -0.020203  0.137603  0.133750 -0.276498   0.137252  0.003451   \n",
       "dow        -0.046424 -0.036220 -0.038918 -0.035233   0.003274 -0.169788   \n",
       "year       -0.019157  0.040913  0.039222 -0.083546  -0.008740  0.029875   \n",
       "ideal      -0.145407  0.727266  0.701874 -0.141678  -0.051489 -0.022858   \n",
       "\n",
       "            workingday    season      hour       dow      year     ideal  \n",
       "weather       0.042061 -0.014524 -0.020203 -0.046424 -0.019157 -0.145407  \n",
       "temp          0.069153  0.312025  0.137603 -0.036220  0.040913  0.727266  \n",
       "atemp         0.067594  0.319380  0.133750 -0.038918  0.039222  0.701874  \n",
       "humidity      0.014316  0.150625 -0.276498 -0.035233 -0.083546 -0.141678  \n",
       "windspeed    -0.001937 -0.149773  0.137252  0.003274 -0.008740 -0.051489  \n",
       "holiday      -0.240847 -0.032516  0.003451 -0.169788  0.029875 -0.022858  \n",
       "workingday    1.000000  0.010879  0.002185 -0.698028 -0.007959  0.023068  \n",
       "season        0.010879  1.000000 -0.006117 -0.007448 -0.010742  0.156455  \n",
       "hour          0.002185 -0.006117  1.000000 -0.002893 -0.003867  0.113745  \n",
       "dow          -0.698028 -0.007448 -0.002893  1.000000  0.000977 -0.009208  \n",
       "year         -0.007959 -0.010742 -0.003867  0.000977  1.000000  0.000788  \n",
       "ideal         0.023068  0.156455  0.113745 -0.009208  0.000788  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'gbm_pred.shape: {gbm_pred.shape}   gbm_actual.shape: {gbm_actual.shape}   gbm_rmsle: {gbm_rmsle}')\n",
    "all_df[gbm_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3470085410836689\n"
     ]
    }
   ],
   "source": [
    "# the blend gives a better score on the leaderboard, even though it does not on the validation set\n",
    "y_pred = np.round(.4*rf_pred + .6*gbm_pred)\n",
    "print(get_rmsle(y_pred, rf_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n",
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n"
     ]
    }
   ],
   "source": [
    "rf_pred = predict_on_test_set(rf_model, rf_cols)\n",
    "gbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n",
    "\n",
    "y_pred = np.round(.4*rf_pred + .6*gbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predictions for submission\n",
    "submit_manual_blend_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_blend_df['count'] = y_pred\n",
    "submit_manual_blend_df.to_csv('output/submit_manual_blend_20211012_1.csv', index=False)\n",
    "\n",
    "submit_manual_rf_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_rf_df['count'] = rf_pred\n",
    "submit_manual_rf_df.to_csv('output/submit_rf_20211012_1.csv', index=False)\n",
    "\n",
    "submit_manual_gbm_df = test_df[['datetime', 'count']].copy()\n",
    "submit_manual_gbm_df['count'] = gbm_pred\n",
    "submit_manual_gbm_df.to_csv('output/submit_gbm_20211012_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0 RandomForestRegressor\n",
    "rf_params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "rf_cols = [\n",
    "    'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak'\n",
    "    ]\n",
    "# Level 0 GradientBoostingRegressor\n",
    "gbm_params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**gbm_params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    'hour', 'dow', 'year', 'ideal', 'count_season',\n",
    "]\n",
    "clf_input_cols = [rf_cols, gbm_cols]\n",
    "clfs = [rf_model, gbm_model]\n",
    "# Create train and test sets for blending and Pre-allocate the data\n",
    "blend_train = np.zeros((train_df.shape[0], len(clfs)))\n",
    "blend_test = np.zeros((test_df.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each classifier, we train the classifier with its corresponding input_cols \n",
    "# and record the predictions on the train and the test set\n",
    "for clf_index, (input_cols, clf) in enumerate(zip(clf_input_cols, clfs)):\n",
    "    \n",
    "    # prepare training and validation set\n",
    "    X_train, y_train_r, y_train_c = prep_train_data(train_df, input_cols)\n",
    "    \n",
    "    # prepare testing set\n",
    "    X_test = test_df[input_cols].values\n",
    "    \n",
    "    model_r = clf.fit(X_train, y_train_r)\n",
    "    y_pred_train_r = np.exp(model_r.predict(X_train)) - 1\n",
    "    y_pred_test_r = np.exp(model_r.predict(X_test)) - 1\n",
    "\n",
    "    model_c = clf.fit(X_train, y_train_c)\n",
    "    y_pred_train_c = np.exp(model_c.predict(X_train)) - 1\n",
    "    y_pred_test_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "    y_pred_train_comb = np.round(y_pred_train_r + y_pred_train_c)\n",
    "    y_pred_train_comb[y_pred_train_comb < 0] = 0\n",
    "    \n",
    "    y_pred_test_comb = np.round(y_pred_test_r + y_pred_test_c)\n",
    "    y_pred_test_comb[y_pred_test_comb < 0] = 0\n",
    "    \n",
    "    blend_train[:, clf_index] = y_pred_train_comb\n",
    "    blend_test[:, clf_index] = y_pred_test_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38011939 0.66365917]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9676364408685162"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level 1 Belending Classifier using LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "bclf = LinearRegression(fit_intercept=False)\n",
    "bclf.fit(blend_train, train_df['count'])\n",
    "# What is the weighted combination of the base classifiers?\n",
    "print(bclf.coef_)\n",
    "# Stacked and Blending predictions\n",
    "y_pred_blend = np.round(bclf.predict(blend_test))\n",
    "# R^2 score\n",
    "bclf.score(blend_train, train_df['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predictions for submission\n",
    "submit_stack_blend_df = test_df[['datetime', 'count']].copy()\n",
    "submit_stack_blend_df['count'] = y_pred_blend\n",
    "submit_stack_blend_df.to_csv('output/submit_stack_blend_20211012_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>sticky</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat</th>\n",
       "      <th>wind_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  sticky  temp_cat  \\\n",
       "datetime                                                           \n",
       "2011-01-01 00:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 01:00:00        312498     0      0       0       1.0   \n",
       "2011-01-01 02:00:00        312498     0      0       0       1.0   \n",
       "\n",
       "                     humidity_cat  wind_cat  \n",
       "datetime                                     \n",
       "2011-01-01 00:00:00           4.0       0.0  \n",
       "2011-01-01 01:00:00           4.0       0.0  \n",
       "2011-01-01 02:00:00           4.0       0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
