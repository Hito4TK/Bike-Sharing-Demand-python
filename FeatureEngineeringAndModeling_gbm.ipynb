{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV,LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.style.use('bmh')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['data_set'] = 'train'\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df['data_set'] = 'test'\n",
    "# combine train and test data into one df\n",
    "test_df['registered'] = 0\n",
    "test_df['casual'] = 0\n",
    "test_df['count'] = 0\n",
    "\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "# parse datetime colum & add new time related columns\n",
    "dt = pd.DatetimeIndex(all_df['datetime'])\n",
    "all_df.set_index(dt, inplace=True)\n",
    "\n",
    "# logarithmic transformation of dependent cols\n",
    "# (adding 1 first so that 0 values don't become -inf)\n",
    "for col in ['casual', 'registered', 'count']:\n",
    "    all_df[f'{col}_log'] = np.log(all_df[col] + 1)\n",
    "\n",
    "all_df['date'] = dt.date # yyyymmdd\n",
    "all_df['day'] = dt.day # dd\n",
    "all_df['month'] = dt.month # mm\n",
    "all_df['year'] = dt.year # yyyy\n",
    "all_df['hour'] = dt.hour # hh\n",
    "all_df['dow'] = dt.dayofweek #曜日 Mon:0 Tue:1 Wed:2 Thu:3 Fri:4 Sat:5 Sun:6\n",
    "all_df['woy'] = dt.isocalendar().week #その日の週が年間で見ると何番目の週かを表す数字 [dt.weekofyear]は deprecated\n",
    "\n",
    "# add a count_season column using join\n",
    "by_season = all_df[all_df['data_set'] == 'train'].copy().groupby(['season'])[['count']].agg(sum)\n",
    "by_season.columns = ['count_season']\n",
    "all_df = all_df.join(by_season, on='season')\n",
    "\n",
    "\n",
    "# feature engineer a new column whether its a peak hour or not\n",
    "all_df['peak'] = all_df[['hour', 'workingday']]\\\n",
    "    .apply(lambda df: 3 if ((df['workingday'] == 1 and (df['hour'] == 8 or 17 <= df['hour'] <= 18)) \\\n",
    "                            or (df['workingday'] == 0 and 11 <= df['hour'] <= 17)) else \\\n",
    "                            ( 2 if ((df['workingday'] == 1 and (df['hour'] == 7 or df['hour'] == 9 or df['hour'] == 16 or 19 <= df['hour'] <= 20)) \\\n",
    "                            or (df['workingday'] == 0 and (df['hour'] == 10 or 18 <= df['hour'] <= 19))) else \\\n",
    "                            ( 1 if ((df['workingday'] == 1 and (10 <= df['hour'] <= 15 or 21 <= df['hour'] <= 22)) \\\n",
    "                            or (df['workingday'] == 0 and (8 <= df['hour'] <= 9 or 20 <= df['hour'] <= 23))) else 0)), axis = 1)\n",
    "\n",
    "#ここの修正の仕方は、間違っているので要修正！\n",
    "# sandy\n",
    "#all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "#    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else 0, axis = 1)\n",
    "# 修正後↓\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday', 'year']]\\\n",
    "    .apply(lambda df: 1 if (df['year'] == 2012 and df['month'] == 10 and df['day'] == 30) else df['holiday'], axis = 1)\n",
    "\n",
    "\n",
    "# christmas and others\n",
    "all_df['holiday'] = all_df[['month', 'day', 'holiday']]\\\n",
    "    .apply(lambda df: 1 if (df['month'] == 12 and df['day'] in [24, 26, 31]) else df['holiday'], axis = 1)\n",
    "all_df['workingday'] = all_df[['month', 'day', 'workingday']]\\\n",
    "    .apply(lambda df: 0 if df['month'] == 12 and df['day'] in [24, 31] else df['workingday'], axis = 1)\n",
    "# これは流石に気づかない気がする。。。気づけない気がする。。。\n",
    "def get_day(day_start):\n",
    "    day_end = day_start + pd.offsets.DateOffset(hours=23)\n",
    "    return pd.date_range(day_start, day_end, freq=\"H\")\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"workingday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"workingday\"] = 1\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"workingday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"workingday\"] = 0\n",
    "\n",
    "# tax day\n",
    "all_df.loc[get_day(datetime(2011, 4, 15)), \"holiday\"] = 0\n",
    "all_df.loc[get_day(datetime(2012, 4, 16)), \"holiday\"] = 0\n",
    "\n",
    "# thanksgiving friday\n",
    "all_df.loc[get_day(datetime(2011, 11, 25)), \"holiday\"] = 1\n",
    "all_df.loc[get_day(datetime(2012, 11, 23)), \"holiday\"] = 1\n",
    "\n",
    "#storms\n",
    "all_df.loc[get_day(datetime(2012, 5, 21)), \"holiday\"] = 1\n",
    "\n",
    "#tornado\n",
    "all_df.loc[get_day(datetime(2012, 6, 1)), \"holiday\"] = 1\n",
    "# from histogram\n",
    "all_df['ideal'] = all_df[['temp', 'windspeed']]\\\n",
    "    .apply(lambda df: 1 if (df['temp'] > 27 and df['windspeed'] < 30) else 0, axis = 1)\n",
    "    \n",
    "all_df['wet'] = all_df[['humidity', 'workingday']]\\\n",
    "    .apply(lambda df: 1 if (df['workingday'] == 1 and df['humidity'] >= 60) else 0, axis = 1)\n",
    "\n",
    "# temperature\n",
    "all_df.loc[all_df['temp'] < 10,'temp_cat'] = 1\n",
    "all_df.loc[(all_df['temp'] >= 10) & (all_df['temp'] < 15),'temp_cat'] = 2\n",
    "all_df.loc[(all_df['temp'] >= 15) & (all_df['temp'] < 20),'temp_cat'] = 3\n",
    "all_df.loc[(all_df['temp'] >= 20) & (all_df['temp'] < 25),'temp_cat'] = 4\n",
    "all_df.loc[(all_df['temp'] >= 25) & (all_df['temp'] < 30),'temp_cat'] = 5\n",
    "all_df.loc[(all_df['temp'] >= 30) & (all_df['temp'] < 35),'temp_cat'] = 6\n",
    "all_df.loc[(all_df['temp'] >= 35),'temp_cat'] = 7\n",
    "\n",
    "# humidity many category\n",
    "all_df.loc[all_df['humidity'] < 10,'humidity_cat'] = 0\n",
    "all_df.loc[(all_df['humidity'] >= 10) & (all_df['humidity'] < 20),'humidity_cat'] = 1\n",
    "all_df.loc[(all_df['humidity'] >= 20) & (all_df['humidity'] < 30),'humidity_cat'] = 2\n",
    "all_df.loc[(all_df['humidity'] >= 30) & (all_df['humidity'] < 40),'humidity_cat'] = 3\n",
    "all_df.loc[(all_df['humidity'] >= 40) & (all_df['humidity'] < 50),'humidity_cat'] = 4\n",
    "all_df.loc[(all_df['humidity'] >= 50) & (all_df['humidity'] < 60),'humidity_cat'] = 5\n",
    "all_df.loc[(all_df['humidity'] >= 60) & (all_df['humidity'] < 70),'humidity_cat'] = 6\n",
    "all_df.loc[(all_df['humidity'] >= 70) & (all_df['humidity'] < 80),'humidity_cat'] = 7\n",
    "all_df.loc[(all_df['humidity'] >= 80) & (all_df['humidity'] < 90),'humidity_cat'] = 8\n",
    "all_df.loc[(all_df['humidity'] >= 90),'humidity_cat'] = 9\n",
    "\n",
    "# windspeed\n",
    "all_df.loc[all_df['windspeed'] < 5,'wind_cat'] = 0\n",
    "all_df.loc[(all_df['windspeed'] >= 5) & (all_df['windspeed'] < 10),'wind_cat'] = 1\n",
    "all_df.loc[(all_df['windspeed'] >= 10) & (all_df['windspeed'] < 15),'wind_cat'] = 2\n",
    "all_df.loc[(all_df['windspeed'] >= 15) & (all_df['windspeed'] < 20),'wind_cat'] = 3\n",
    "all_df.loc[(all_df['windspeed'] >= 20) & (all_df['windspeed'] < 25),'wind_cat'] = 4\n",
    "all_df.loc[(all_df['windspeed'] >= 25) & (all_df['windspeed'] < 30),'wind_cat'] = 5\n",
    "all_df.loc[(all_df['windspeed'] >= 30) & (all_df['windspeed'] < 35),'wind_cat'] = 6\n",
    "all_df.loc[(all_df['windspeed'] >= 35) & (all_df['windspeed'] < 40),'wind_cat'] = 7\n",
    "all_df.loc[(all_df['windspeed'] >= 40) & (all_df['windspeed'] < 45),'wind_cat'] = 8\n",
    "all_df.loc[(all_df['windspeed'] >= 45),'wind_cat'] = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>wet</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat</th>\n",
       "      <th>wind_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  wet  temp_cat  humidity_cat  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00        312498     0      0    0       1.0           8.0   \n",
       "2011-01-01 01:00:00        312498     0      0    0       1.0           8.0   \n",
       "2011-01-01 02:00:00        312498     0      0    0       1.0           8.0   \n",
       "\n",
       "                     wind_cat  \n",
       "datetime                       \n",
       "2011-01-01 00:00:00       0.0  \n",
       "2011-01-01 01:00:00       0.0  \n",
       "2011-01-01 02:00:00       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
       "       'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count',\n",
       "       'data_set', 'casual_log', 'registered_log', 'count_log', 'date', 'day',\n",
       "       'month', 'year', 'hour', 'dow', 'woy', 'count_season', 'peak', 'ideal',\n",
       "       'wet', 'temp_cat', 'humidity_cat', 'wind_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of randomly splitting our training data \n",
    "# for cross validation, let's construct a framework that's more\n",
    "# in line with how the data is divvied up for this competition\n",
    "# (given first 19 days of each month, what is demand for remaining days)\n",
    "# so, let's split our training data into 2 time contiguous datasets\n",
    "# for fitting and validating our model (days 1-14 vs. days 15-19).\n",
    "\n",
    "# also, since submissions are evaluated based on the\n",
    "# root mean squared logarithmic error (RMSLE), let's replicate\n",
    "# that computation as we test and tune our model.\n",
    "\n",
    "train_df = all_df[all_df['data_set'] == 'train']\n",
    "test_df = all_df[all_df['data_set'] == 'test']\n",
    "\n",
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def custom_train_valid_split(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    valid = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def prep_train_data(data, input_cols):\n",
    "    X = data[input_cols].values\n",
    "    y_r = data['registered_log'].values\n",
    "    y_c = data['casual_log'].values\n",
    "\n",
    "    return X, y_r, y_c\n",
    "\n",
    "# predict on validation set & transform output back from log scale\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    \n",
    "    train, valid = custom_train_valid_split(train_df)\n",
    "    y_pred_comb_l = []\n",
    "    y_actual_comb_l = []\n",
    "\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "\n",
    "            ##print(f'Now,{year_val} {month_val} training and validating...')\n",
    "            # prepare training & validation set\n",
    "            train_tmp = train.query('year <= @year_val and month <= @month_val')\n",
    "            valid_tmp = valid.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_tmp, input_cols)\n",
    "            X_valid, y_valid_r, y_valid_c = prep_train_data(valid_tmp, input_cols)\n",
    "\n",
    "            # training and validating\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_valid)) - 1\n",
    "\n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_valid)) - 1\n",
    "\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "            y_actual_comb = np.exp(y_valid_r) + np.exp(y_valid_c) - 2\n",
    "            y_actual_comb_l.extend(y_actual_comb)\n",
    "\n",
    "            #rmsle = get_rmsle(y_pred_comb, y_actual_comb)\n",
    "            #rmsle_l.append(rmsle)\n",
    "    \n",
    "    rmsle = get_rmsle(np.array(y_pred_comb_l),np.array(y_actual_comb_l))\n",
    "    \n",
    "    return (np.array(y_pred_comb_l), np.array(y_actual_comb_l), rmsle)\n",
    "\n",
    "\n",
    "# predict on test set & transform output back from log scale\n",
    "def predict_on_test_set(model, input_cols):\n",
    "    \n",
    "    y_pred_comb_l = []\n",
    "    for year_val in [2011,2012]:\n",
    "        for month_val in range(1,13):\n",
    "            \n",
    "            # prepare training set\n",
    "            print(f'Now,{year_val} {month_val} testing...')\n",
    "            train_df_tmp = train_df.query('year <= @year_val and month <= @month_val')\n",
    "            test_df_tmp = test_df.query('year == @year_val and month == @month_val')\n",
    "\n",
    "            X_train, y_train_r, y_train_c = prep_train_data(train_df_tmp, input_cols)\n",
    "\n",
    "            # prepare testing set\n",
    "            X_test = test_df_tmp[input_cols].values\n",
    "            \n",
    "            model_c = model.fit(X_train, y_train_c)\n",
    "            y_pred_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "            model_r = model.fit(X_train, y_train_r)\n",
    "            y_pred_r = np.exp(model_r.predict(X_test)) - 1\n",
    "            \n",
    "            # add casual & registered predictions together\n",
    "            y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "            y_pred_comb[y_pred_comb < 0] = 0\n",
    "            y_pred_comb_l.extend(y_pred_comb)\n",
    "\n",
    "    \n",
    "    return np.array(y_pred_comb_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est: 100  l_rate:0.1  min_sam_leaf:10  subsample:0.7  max_dep:5\n",
      "0.3500989386575082\n",
      "gbm_pred.shape: (2286,)   gbm_actual.shape: (2286,)   gbm_rmsle: 0.3500989386575082\n",
      "n_est: 100  l_rate:0.1  min_sam_leaf:10  subsample:0.7  max_dep:5\n"
     ]
    }
   ],
   "source": [
    "#params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "#gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    #'holiday', 'workingday', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "    'hour', 'dow', 'year', 'ideal', #'count_season',\n",
    "]\n",
    "\n",
    "n_estimators = [100]\n",
    "#n_estimators = [100,150,200]\n",
    "learning_rate = [0.1]\n",
    "#learning_rate = [0.01,0.05,0.1,0.15]\n",
    "min_samples_leaf = [10]\n",
    "#min_samples_leaf = [1,3,5,7,10,12,15]\n",
    "#min_samples_split = [2]\n",
    "#min_samples_split = [2,4,6,8,10]\n",
    "max_depth = [5]\n",
    "#max_depth = [3,5,7,9]\n",
    "subsample = [0.7]\n",
    "\n",
    "best_n_est = 0\n",
    "best_l_rate = 0\n",
    "best_min_sam_leaf = 0\n",
    "best_max_dep = 0\n",
    "best_subsample = 0\n",
    "\n",
    "best_score_gbm = 10\n",
    "best_gbm_pred = []\n",
    "\n",
    "for n_est in n_estimators:\n",
    "    for l_rate in learning_rate:\n",
    "        for min_sam_leaf in min_samples_leaf:\n",
    "            for subsample_item in subsample:\n",
    "                for max_dep in max_depth:\n",
    "                    print(f'n_est: {n_est}  l_rate:{l_rate}  min_sam_leaf:{min_sam_leaf}  subsample:{subsample_item}  max_dep:{max_dep}')\n",
    "                    gbm_model = GradientBoostingRegressor(n_estimators=n_est,learning_rate=l_rate, min_samples_leaf=min_sam_leaf,subsample=subsample_item,max_depth=max_dep,loss='ls',random_state=0)\n",
    "                    (gbm_pred, gbm_actual, gbm_rmsle) = predict_on_validation_set(gbm_model, gbm_cols)\n",
    "                    print(gbm_rmsle)\n",
    "                    if gbm_rmsle < best_score_gbm:\n",
    "                        best_n_est = n_est\n",
    "                        best_l_rate = l_rate\n",
    "                        best_min_sam_leaf = min_sam_leaf\n",
    "                        best_subsample = subsample_item\n",
    "                        best_max_dep = max_dep\n",
    "\n",
    "                        best_score_gbm = gbm_rmsle\n",
    "                        best_gbm_pred = gbm_pred\n",
    "\n",
    "print(f'gbm_pred.shape: {best_gbm_pred.shape}   gbm_actual.shape: {gbm_actual.shape}   gbm_rmsle: {best_score_gbm}')\n",
    "print(f'n_est: {best_n_est}  l_rate:{best_l_rate}  min_sam_leaf:{best_min_sam_leaf}  subsample:{best_subsample}  max_dep:{best_max_dep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_trn_df,temp_val_df = custom_train_valid_split(train_df)\n",
    "submit_gbm_df = temp_val_df[['datetime', 'count']].copy()\n",
    "submit_gbm_df['count'] = best_gbm_pred\n",
    "submit_gbm_df.to_csv('output2/submit_gbm_val_20211022_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now,2011 1 testing...\n",
      "Now,2011 2 testing...\n",
      "Now,2011 3 testing...\n",
      "Now,2011 4 testing...\n",
      "Now,2011 5 testing...\n",
      "Now,2011 6 testing...\n",
      "Now,2011 7 testing...\n",
      "Now,2011 8 testing...\n",
      "Now,2011 9 testing...\n",
      "Now,2011 10 testing...\n",
      "Now,2011 11 testing...\n",
      "Now,2011 12 testing...\n",
      "Now,2012 1 testing...\n",
      "Now,2012 2 testing...\n",
      "Now,2012 3 testing...\n",
      "Now,2012 4 testing...\n",
      "Now,2012 5 testing...\n",
      "Now,2012 6 testing...\n",
      "Now,2012 7 testing...\n",
      "Now,2012 8 testing...\n",
      "Now,2012 9 testing...\n",
      "Now,2012 10 testing...\n",
      "Now,2012 11 testing...\n",
      "Now,2012 12 testing...\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingRegressor(n_estimators=best_n_est,learning_rate=best_l_rate, min_samples_leaf=best_min_sam_leaf,min_samples_split=best_min_sam_split,max_depth=best_max_dep,max_features ='auto',loss='ls',random_state=0)\n",
    "gbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n",
    "\n",
    "# output predictions for submission\n",
    "submit_gbm_df = test_df[['datetime', 'count']].copy()\n",
    "submit_gbm_df['count'] = gbm_pred\n",
    "submit_gbm_df.to_csv('output2/submit_gbm_20211022_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>data_set</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>woy</th>\n",
       "      <th>count_season</th>\n",
       "      <th>peak</th>\n",
       "      <th>ideal</th>\n",
       "      <th>wet</th>\n",
       "      <th>temp_cat</th>\n",
       "      <th>humidity_cat</th>\n",
       "      <th>wind_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>312498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                datetime  season  holiday  workingday  \\\n",
       "datetime                                                                \n",
       "2011-01-01 00:00:00  2011-01-01 00:00:00       1        0           0   \n",
       "2011-01-01 01:00:00  2011-01-01 01:00:00       1        0           0   \n",
       "2011-01-01 02:00:00  2011-01-01 02:00:00       1        0           0   \n",
       "\n",
       "                     weather  temp   atemp  humidity  windspeed  casual  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00        1  9.84  14.395        81        0.0       3   \n",
       "2011-01-01 01:00:00        1  9.02  13.635        80        0.0       8   \n",
       "2011-01-01 02:00:00        1  9.02  13.635        80        0.0       5   \n",
       "\n",
       "                     registered  count data_set  casual_log  registered_log  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00          13     16    train    1.386294        2.639057   \n",
       "2011-01-01 01:00:00          32     40    train    2.197225        3.496508   \n",
       "2011-01-01 02:00:00          27     32    train    1.791759        3.332205   \n",
       "\n",
       "                     count_log        date  day  month  year  hour  dow  woy  \\\n",
       "datetime                                                                       \n",
       "2011-01-01 00:00:00   2.833213  2011-01-01    1      1  2011     0    5   52   \n",
       "2011-01-01 01:00:00   3.713572  2011-01-01    1      1  2011     1    5   52   \n",
       "2011-01-01 02:00:00   3.496508  2011-01-01    1      1  2011     2    5   52   \n",
       "\n",
       "                     count_season  peak  ideal  wet  temp_cat  humidity_cat  \\\n",
       "datetime                                                                      \n",
       "2011-01-01 00:00:00        312498     0      0    0       1.0           8.0   \n",
       "2011-01-01 01:00:00        312498     0      0    0       1.0           8.0   \n",
       "2011-01-01 02:00:00        312498     0      0    0       1.0           8.0   \n",
       "\n",
       "                     wind_cat  \n",
       "datetime                       \n",
       "2011-01-01 00:00:00       0.0  \n",
       "2011-01-01 01:00:00       0.0  \n",
       "2011-01-01 02:00:00       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
